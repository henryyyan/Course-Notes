\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{relsize}
\usepackage{titlesec}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{graphics}
\usepackage{tcolorbox}
\usepackage{hyperref}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{xcolor}
\usepackage{enumerate}
\usepackage[T1]{fontenc}
\usepackage{titling}
\usepackage{changepage}
\usepackage{mathrsfs}
\usepackage{biblatex}
\usepackage{float}
\usepackage{soul,color,xcolor}
\usepackage{esvect}

\usepackage[margin=1.0in]{geometry}

\DeclareMathOperator{\N}{\mathbb{N}}
\DeclareMathOperator{\Z}{\mathbb{Z}}
\DeclareMathOperator{\Q}{\mathbb{Q}}
\DeclareMathOperator{\R}{\mathbb{R}}
\DeclareMathOperator{\C}{\mathbb{C}}
\DeclareMathOperator{\F}{\mathbb{F}}

\DeclareMathOperator{\im}{Im}
\DeclareMathOperator{\aut}{Aut}
\DeclareMathOperator{\inn}{Inn}
\DeclareMathOperator{\Char}{char}
\DeclareMathOperator{\syl}{Syl}
\DeclareMathOperator{\ch}{ch}
\DeclareMathOperator{\End}{End}

\title{Abstract Algebra by Dummit and Foote}
\author{Henry Yan}
\date{November 2023}


\begin{document}

\maketitle

\subsection*{Notes}
Any injective or bijective map (either or suffices) from a set of $n$ elements to another set of $n$ elements is necessarily bijective. \\ \\
All cyclic groups are Abelian, but an Abelian group is not necessarily cyclic. \\ \\
For some element $a \in A$, $\overline{a}$ is the equivalence class of $a$. \\ \\
The go-to method for proving equality of sets is inclusion in both directions.
\subsection*{Basics and Groups}
\textbf{Definition 1.4 - Image/Range}: Let $S$ and $T$ be two sets, and let $f: S \rightarrow T$ be a map. We define the \textit{image} (also known as \textit{range}) of $f$ to be: $$\im(f) := \{y \in T | \exists x \in S \text{ such that } f(x) = y\}.$$ \\
\textbf{Definition 1.5 - Preimage}: Let $f: S \rightarrow T$, and suppose $U \subseteq T$. Then we define the \textit{preimage} of $U$ under $f$ to be $$f^{-1}(U) := \{s \in S | f(s) \in U\}.$$ \\
\textbf{Definition 1.13 - Equivalence Relation}: An \textit{equivalence relation} on a set $S$ is a subset $U \subseteq S \times S$ satisfying: \begin{enumerate}
        \item Reflexive: $\forall x \in S, (x, x) \in U$
    \item Symmetric: $(x, y) \in U \iff (y, x) \in U$
    \item Transitive: Given $ x, y, z \in S$, $(x, y) \in U$ and $(y, z) \in U \implies (x, z) \in U$.
\end{enumerate} We often write $x \sim y$ to mean that $x, y$ are equivalent. \\ \\
\textbf{Definition 1.14 - Equivalence Class}. Let $\sim$ be an equivalence relation on the set $S$. Let $x \in S$. The \textit{equivalence class} containing $x$ is the subset $$[x] := \{y \in S | y \sim x\} \subset S.$$ \\
\textbf{Definition 1.16 - Partition}: Let $S$ be a set. Let $\{X_i\}$ be a collection of subsets for $i \in I$, some index set. We say that $\{X_i\}$ forms a \textit{partition} of $S$ if each $X_i$ is non-empty, they are pairwise disjoint and their union is $S$.
\subsection*{3. Groups}
\textbf{Definition - Group}: A group is a set $G$, together with a binary
operation $*$, such that the following hold: \begin{enumerate}
    \item (Associativity): $(a * b) * c = a * (b * c)$, $\forall a, b, c \in G$.
    \item (Existence of identity): $\exists e \in G$ such that $a * e = e * a = a$, $\forall a \in G$.
    \item (Existence of inverses): Given $a \in G, \exists b \in G$ such that $a * b = b * a = e$.
\end{enumerate} $ $ \\
We define a \textbf{direct product} of groups for two groups $A, B$ by $A \times B = \{(a, b) | a \in A, b \in B\}$, and $(a_1, b_1)(a_2, b_2) = (a_1a_2, b_1b_2)$. Then $A \times B$ also forms a group. \\ \\
\textbf{Definition - Abelian}. A group $(G, *)$ is called \textit{Abelian} if it satisfies $$a * b = b * a, \forall a, b \in G.$$ This is also called the \textit{commutative property}. \\ \\
\textbf{Definition - Order of an Element}: For $G$ a group and $x \in G$ define the order of $x$ to be the smallest positive integer $n$ such that $x^n = 1$, and denote this integer by $|x|$. In this case $x$ is said to be of \textbf{order} $n$. If no positive power of $x$ is the identity, the order of $x$ is defined to be infinity and $x$ is said to be of \textbf{infinite order}. \\ \\
\textbf{Definition - Homomorphism}: Let $(G, *)$ and $(H, \circ)$ be two groups. A \textit{homomorphism} $f$, from $G$ to $H$, is a map of sets $f: G \rightarrow H$, such that $f(x * y) = f(x) \circ f(y)$, $\forall x, y \in G$. If $G = H$ and $f = Id_G$ we call $f$ the \textit{identity homomorphism}. \\ \\
\textbf{Definition - Isomorphism}: A homomorphism $f: G \rightarrow H$ which is bijective is called an \textit{isomorphism}. Two groups are said to be isomorphic if there exists an isomorphism between them. \\ \\
\textbf{Definition - Endomorphism/Automorphism}: A homomorphism from a group to itself (i.e. $f: G \rightarrow G$) is called an \textit{endomorphism}. An endomorphism which is also an isomorphism is
called an \textit{automorphism}. \\ \\
\textbf{Proposition 3.6/3.7/3.8}: \begin{enumerate}
    \item[3.6.] Identity is unique.
    \item[3.7.] Inverses are unique.
    \item[3.8.] For $x, y \in G$, $(x * y)^{-1} = y^{-1} * x^{-1}$.
\end{enumerate} $ $ \\
\textbf{Proposition 3.9 - Homomorphism Facts}: Let $(G, *)$ and $(H, \circ)$ be two groups with identities, $e_G$ and $e_H$, respectively, and $f: G \rightarrow H$ a homomorphism. \begin{enumerate}
    \item $f(e_G) = e_H,$
    \item $f(x^{-1}) = (f(x))^{-1}, \forall x \in G.$
\end{enumerate} $ $ \\
\textbf{Definition - Subgroup}. Let $(G, *)$ be a group. A subgroup of $G$ is a subset $H \subset G$ such that \begin{enumerate}
    \item $e \in H$,
    \item $x, y \in H \implies x * y \in H$,
    \item $x \in H \iff x^{-1} \in H$.
\end{enumerate} $ $ \\
\textbf{Proposition} Let $H, K \subset G$ be subgroups, then $H \cap K \subset G$ is a also subgroup of $G$. \\ \\
\textbf{Definition}: Let $(G, *)$ be a group and let $H \subset G$ be a subgroup. Let us define a relation on $G$ using $H$ as follows: given $x, y \in G,$ $$x \sim y \iff x ^{-1} * y \in H.$$ \\
\textbf{Definition - Left Coset}: The equivalence class, or \textit{left coset}, containing $x$ equals $$xH := \{x * h | h \in H\} \subset G.$$ \\
\textbf{Corollary 3.15}: Hence for $x, y \in G, xH = yH \iff x^{-1} * y \in H$. \\ \\
An immediate consequence of Corollary 3.15 is that if $y \in xH$, then $yH = xH$. Thus left cosets can generally be written with different representations in front. \\ \\
\textbf{Definition 3.17 - Index}. Let $(G, *)$ be a group and $H \subset G$ a subgroup. We denote by $G / H$ the set of left cosets of $H$ in $G$. If the size of this set is finite then we say that $H$ has \textit{finite index} in $G$. In this case we write $$(G:H) = |G / H|,$$ and call it the \textit{index} of $H$ in $G$. \\ \\
\textbf{Lagrange's Theorem}: Let $(G, *)$ be a finite group and $H \subset G$ a subgroup. Then $|H|$ divides $|G|$. \\ \\
\textbf{Definition - Group of Permutations}: Let $\Sigma(s)$ denote the group of permutations of a set $S$. \\ \\
\textbf{Definition - Dihedral Group}: Let $D_{2n}$ represent the symmetries of an $n$-gon as a result of actions on the object in 3 dimensions. $|D_{2n}| = 2n$, and $D_{2n} = \langle r, s | r^n = s^2 = 1, rs = sr^{-1} \rangle$. \\ \\
\textbf{Definition - Generators}: A subset $S$ of elements of a group $G$ with the property that every element of $G$ can be written as a (finite) product of elements of $S$ and their inverses is called a set of \textit{generators} of $G$. We shall indicate this notationally by writing $G = \langle S \rangle$ and say $G$ \textit{is generated by} $S$ or $S$ \textit{generates} $G$. Any equations that the generators must satisfy in $G$ are called \textbf{relations}. A \textbf{presentation} of $G = D_{2n}$ is $D_{2n} = \langle r, s | r^n = s^2 = 1, rs = sr^{-1} \rangle$. \\ \\
The \textbf{symmetric group} $S_{\Omega}$ is denotes the set of all bijections (permutations) from $\Omega$ to itself. \\ \\
$S_n$ defines the symmetric group of degree $n$, where the set of elements is $\{1, 2, \dots, n\}$ and $|S_n| = n!$. \\ \\
$S_n$ is non-Abelian for all $n \geq 3$. \\ \\
Disjoint cycles commute. \\ \\
\textbf{Definition - Field}: \begin{enumerate}
    \item A \textit{field} is set $F$ with two binary operations $+$ and $\cdot$ on $F$ such that $(F, +)$ is an Abelian group, with identity 0, and $(F - \{0\}, \cdot)$ is also an Abelian group, and the following \textit{distribute} law holds: $$a \cdot (b + c) = (a \cdot b) + (a \cdot c), \text{ for all } a, b, c \in F.$$
    \item For any field $F$ let $F^\times = F - \{0\}$.
\end{enumerate}
Let $GL_n(F)$ be the set of all $n \times n$ matrices whose entries come from $F$ and whose determinant is non-zero. $GL_n(F)$ is called the \textbf{general linear group of degree} $n$. \\ \\
Theorems at the end of 1.4: \begin{enumerate}
    \item If $F$ is a field and $|F| < \infty$, then $|F| = p^m$ for some prime $p$ and integer $m$,
    \item if $|F| = q < \infty,$ then $|GL_n(F)| = (q^n - 1)(q^n - q) \dots (q^n - q^{n - 1})$.
\end{enumerate} $ $ \\ 
\textbf{Definition - Quaternion Group}: The \textit{Quaternion group}, $Q_8$, is defined by $$Q_8 = \{1, -1, i, -i, j, -j, k, -k\}$$ with product $\cdot$ computed as follows: \begin{enumerate}
    \item $1 \cdot a = a \cdot 1 = a$, for all $a \in Q_8$
    \item $(-1) \cdot (-1) = 1, (-1) \cdot a = a \cdot (-1) = -a$
    \item $i \cdot i = j \cdot j = k \cdot k = -1$
    \item $i \cdot j = k, j \cdot i = -k$
    \item $j \cdot k = i, k \cdot j = -i$
    \item $k \cdot i = j, i \cdot k = -j$
\end{enumerate} $ $ \\
$Q_8 = \langle i, j | i^4 = 1, j^2 = i^2, ji = ij^{-1} \rangle$. \\ \\
For an isomorphism $\varphi: G \rightarrow H$, we have the following properties: \begin{enumerate}
    \item $|G| = |H|$.
    \item $G$ is Abelian iff $H$ is Abelian.
    \item For all $x \in G$, $|x| = |\varphi(x)|$.
    \item If we have a presentation for $G = \langle s_1, s_2, \dots, s_n \rangle$, then $H$ is generated by $\langle r_1, r_2, \dots, r_n \rangle $ = $ \langle \varphi(s_1), \varphi(s_2), \dots, \varphi(s_n) \rangle$, and the relations among the $s_i$'s hold similarly for the $r_i$'s (since $s_i$'s are elements of $G$).
\end{enumerate} $ $ \\
\textbf{Definition - Group Action}: A \textit{group action} of a group $G$ on a set $A$ is a map from $G \times A \rightarrow A$ satisfying the following properties: \begin{enumerate}
    \item $g_1 \cdot (g_2 \cdot a) = (g_1g_2) \cdot a$, for all $g_1, g_2 \in G, a \in A$,
    \item $1 \cdot a = a$, for all $a \in A$
\end{enumerate} $ $ \\
Alternatively, we say that $G$ is a group acting on a set $A$. \\ \\
Define $\sigma_g: A \rightarrow A, \sigma_g(a) = g \cdot a$, then there are 2 important facts \begin{enumerate}
    \item for each fixed $g \in G, \sigma_g$ is a permutation of $A$, and
    \item the map $\varphi: G \rightarrow S_A$ defined by $\varphi(g) = \sigma_g$ is a homomorphism. $\varphi$ is called the \textit{permutation representation} associated to the given action.
\end{enumerate} $ $ \\
In particular, this could be called a left action, as a right action could be defined similarly. \\ \\
The action defined by $ga = a, \forall g \in G, a \in A$, is called the \textit{trivial action} and $G$ is said to \textit{act trivially} on $A$. \\ \\
If $G$ acts on $A$ and each element of $G$ induce different permutations of $A$, then the action is said to be \textit{faithful}, i.e. injective. \\ \\
The \textit{kernel} of the action $G$ on $A$ is defined to be $\{g \in G | ga = a, \forall a \in A\}$, namely the elements of $G$ which fix all the elements of $A$. The kernel of the trivial action is all of $G$. \\ \\
\textbf{Definition - Subgroup}: Let $G$ be a group. The subset $H$ of $G$ is a \textit{subgroup} of $G$ if $H$ is nonempty and $H$ is closed under products and inverses (i.e., $x, y \in H$ implies $x^{-1} \in H$ and $xy \in H$). If $H$ is a subgroup of $G$ we shall write $H \leq G$. If $H \neq G$, then we may write $H < G$ to signify a proper subgroup. \\ \\
The \textit{trivial subgroup} refers to a subgroup which contains only the identity element. \\ \\
If $C \leq B$, and $B \leq A$, then we have that $C \leq A$, or $C$ is a subgroup of $A$. This property is called \textit{transitivity}. \\ \\
\textbf{Proposition 2.1 (Subgroup Criterion)}: A subset $H$ of a group $G$ is a subgroup if and only if \begin{enumerate}
    \item $H \neq \emptyset$, and
    \item for all $x, y \in H, xy^{-1} \in H$.
\end{enumerate} $ $ \\
\textbf{Definition - Centralizers}: Define $C_G(A) = \{g \in G| gag^{-1} = a, \forall a \in A\}$. This subset of $G$ is called the \textit{centralizer} of $A$ in $G$. Since $gag^{-1} = a$ iff $ga = ag, C_G(A)$ is the set of elements of $G$ which commute with every element of $A$. \\ \\
The center of any group $G$ is a subset of the centralizer of any subset $A$ in $G$. \\ \\
\textbf{Definition - Center}: Define $Z(G) = \{g \in G | gx = xg, \forall x \in G\}$ as the set of elements commuting with all elements of $G$. This subset of $G$ is called the \textit{center} of $G$. \\ \\
\textbf{Definition - Normalizer}: Define the \textit{normalizer} of $A$ in $G$ to be $N_G(A) = \{g \in G | gAg^{-1} = A\}$. \\ \\
By definition, $C_G(A) \leq N_G(A)$. \\ \\
Each of centralizers, center, and normalizer form subgroups of $G$. \\ \\
\textbf{Definition - Stabilizer}: If a group $G$ is acting on a set $S$, for a fixed element $s \in S$, we define the \textit{stabilizer} of $s$ in $G$ as $$G_s = \{g \in G | g \cdot s = s\}.$$ The stabilizer also forms a subgroup of $G$. \\ \\
\textbf{Definition - Kernel of a Group Action}: The \textit{kernel} of an action $G$ on $S$ is defined as $\ker(G) = \{g \in G| g \cdot s = s, \forall s \in S\}$. \\ \\
\textbf{Definition - Cyclic}: A group $H$ is cyclic if $H$ can be generated by a single element, i.e., $H = \{x^n | n \in \mathbb{Z}\}$, where the usual operation is shorted-handed as multiplication (powers of $x$). \\ \\
In additive notation we may write that $H = \{nx | n \in \mathbb{Z}\}$. In either case we write that $H = \langle x \rangle$ and say that $H$ is generated by $x$, or $x$ is a generator of $H$. \\ \\
\textbf{Proposition 2.2}: If $H = \langle x \rangle$, then $|H| = |x|$ (where if one side of the equality is infinite then so is the other). More specifically, \begin{enumerate}
    \item if $|H| = n < \infty$, then $x^n = 1$ and $1, x, \dots, x^{n - 1}$ are all distinct elements of $H$, and
    \item if $|H| = \infty$, then $x^n = 1 \iff n = 0$ and $x^a \neq x^b$ for all $a \neq b$ in $\Z$.
\end{enumerate} $ $ \\
\textbf{Theorem 2.4}: Any two cyclic groups of the same order are isomorphic. More specifically, \begin{enumerate}
    \item if $n \in \Z^+$ and $\langle x \rangle$ and $\langle y \rangle$ are both cyclic groups of order $n$, then the map \begin{align*}
        \varphi: \langle x \rangle &\rightarrow \langle y \rangle \\
        x^k &\mapsto y^k
    \end{align*}
    is well defined and is an isomorphism.
    \item if $\langle x \rangle$ is an infinite cyclic group, the map \begin{align*}
        \varphi: \Z &\rightarrow \langle x \rangle \\
        k &\mapsto x^k
    \end{align*}
    is well defined and is an isomorphism.
\end{enumerate} $ $ \\
For each $n \in \Z^+$, let $Z_n$ denote the cyclic group of order $n$, written multiplicatively. Note that up to isomorphism, $Z_n \cong \Z/n\Z$ is the unique cyclic group of order $n$. Similarly, $\Z$ (additively) will be used to denote the infinite cyclic group. \\ \\
\textbf{Proposition 2.5}: Let $G$ be a group, $x \in G$, and let $a \in \Z - \{0\}$. \begin{enumerate}
    \item If $|x| = \infty$, then $|x^a| = \infty$.
    \item If $|x| = n < \infty,$ then $|x^a| = \mathlarger{\frac{n}{(n, a)}}$, where $(n, a)$ is the GCD of $n$ and $a$.
    \item In particular, if $|x| = n < \infty$ and $a$ is a positive integer dividing $n$, then $|x^a| = \mathlarger{\frac{n}{a}}$.
\end{enumerate} $ $ \\
\textbf{Proposition 2.6}: Let $H = \langle x \rangle$. \begin{enumerate}
    \item Assume $|x| = \infty$, then $H = \langle x^a \rangle$ iff $a = \pm 1$.
    \item Assume $|x| = n < \infty$, then $H = \langle x^a \rangle$ iff $(a, n) = 1$. In particular, the number of generators of $H$ is $\varphi(n)$, where $\varphi$ is Euler's Totient function.
\end{enumerate} $ $ \\
\textbf{Theorem 2.7}: Let $H = \langle x \rangle$ be a cyclic group. \begin{enumerate}
    \item Every subgroup of $H$ is cyclic. More precisely, if $K \leq H$, then $K = \{1\}$ or $K = \langle x^d \rangle$.
    \item If $|H| = \infty$, then for any distinct nonnegative integers $a$ and $b$, $\langle x^a \rangle \neq \langle x^b \rangle$. Furthermore, for every integer $m$, $\langle x^m \rangle = \langle x^{|m|} \rangle$.
    \item If $|H| = n$, then for each positive integer $a$ dividing $n$ there is a unique subgroup of $H$ of order $a$. This is the subgroup $\langle x^d \rangle$, where $d = n/a$. Furthermore, for every integer $m$, $\langle x^m \rangle = \langle x^{(n, m)} \rangle$ so that the subgroups of $H$ correspond bijectively with the positive divisors of $n$.
\end{enumerate} $ $ \\
For any subgroup $H \leq G$ which contains the element $x$, $\langle x \rangle$ is contained within $H$. As the inclusion of $\langle x \rangle$ simply ensures that the axioms of closure and inverse exist within $H$, for the given element $x$. \\ \\
\textbf{Definition - Subgroup Generated by a Subset}: If $A$ is any subset of the group $G$, define $$\langle A \rangle = \bigcap_{\substack{A \subseteq H \\ H \leq G}} H$$ to be the \textit{subgroup of $G$ generated by $A$}. \\ \\
For multiple subsets $A, B \subseteq G,$ we write $\langle A, B \rangle = \langle A \cup B \rangle$. \\ \\
\textbf{Definition - Words}: Let $$\overline{A} = \{a_1^{\epsilon_1} a_2^{\epsilon_2} \dots a_n^{\epsilon_n} | n \in \Z, n \geq 0 \text{ and } a_i \in A, \epsilon_i = \pm 1 \text{ for each } i\},$$ where $\overline{A} = \{1\}$ if $A = \emptyset$. This is called the \textit{words}, or the set of all finite products of $A$ and inverses of elements of $A$. Note that each of the $a_i$'s in the definition are not necessarily distinct. \\ \\
\textbf{Proposition 2.9}: $\overline{A} = \langle A \rangle$. \\ \\
Another way of writing $$\langle A \rangle = \{a_1^{\alpha_1} a_2^{\alpha_2} \dots a_n^{\alpha_n} | \text{ for each } i, a_i \in A, \alpha_i = \Z, a_i \neq a_{i + 1} \text{ and } n \in \Z^+\}.$$ \\
If $G$ is Abelian, then $$\langle A \rangle = \{a_1^{\alpha_1} a_2^{\alpha_2} \dots a_n^{\alpha_n} | \alpha_i \in \Z \text{ for each } i\}.$$ \\
\textbf{Definition - Lattice}: A lattice of a group $G$ is essentially a graph with $G$ at the top, and $1$ at the bottom, with subgroups of increasing order as you go up. Any two subgroups $A, B$ of $G$ are connected via a line upwards if $B \leq A$. \\ \\
\textbf{Definition - Join}: Given subgroups $H, K \leq G$, we define the join of $H$ and $K$ $\langle H, K \rangle$ as the ``smallest'' subgroup containing both $H$ and $K$. \\ \\
A similar concept for the largest subgroup contained within two subgroups $A, B$ is $A \cap B$, which is necessarily a subgroup by proposition 2.8. \\ \\
\textbf{Definition - Fiber}: For a homomorphism $\varphi: G \rightarrow H$, the \textit{fibers} of $\varphi$ are the sets of elements of $G$ projecting to single elements of $H$. This can be viewed as the inverse of a homomorphism, i.e. the fiber of some element $h \in H$ is $\{g \in G| \varphi(g) = h\}$. We would call this the fiber above $h$. \\ \\
For fibers $X_a, X_b$, we define $X_{ab} = X_aX_b$. \\ \\
The set of fibers forms a group.
\subsection*{Quotient Groups and Homomorphisms}
\textbf{Definition - Kernel}: For a homomorphism $\varphi: G \rightarrow H$, the kernel of $\varphi$ is $$\ker{\varphi} = \{g \in G| \varphi(g) = 1_H\}.$$ \\
\textbf{Proposition 3.1}: For a homomorphism $\varphi: G \rightarrow H$, \begin{enumerate}
    \item $\varphi(1_G) = 1_H$.
    \item $\varphi(g^{-1}) = \varphi(g)^{-1}$
    \item $\varphi(g^{n}) = \varphi(g)^{n}$, for all $n \in \Z$.
    \item $\ker{\varphi}$ is a subgroup of $G$.
    \item $\im{\varphi}$ forms a subgroup of $H$.
\end{enumerate} $ $ \\
\textbf{Definition - Quotient Group}: Let $\varphi: G \rightarrow H$ be a homomorphism with kernel $K$. The \textit{quotient group}, or factor group, $G/K = \overline{G}$ (read $G$ \textit{modulo} $K$ or $G$ \textit{mod} $k$), is the group whose elements are the fiber of $\varphi$ with group operation defined above: namely if $X$ is the fiber above $a$ and $Y$ is the fiber above $b$ then the product of $X$ and $Y$ is defined to be the fiber of above the product $ab$. \\ \\
\textbf{Proposition 3.2}: Let $\varphi: G \rightarrow H$ be a homomorphism with kernel $K$. Let $X \in G/K$ be the fiber above $a$, i.e., $X = \varphi^{-1}(a)$. Then \begin{enumerate}
    \item for any $u \in X$, $X = \{uk| k \in K\}$, and similarly
    \item for any $u \in X$, $X = \{ku| k \in K\}$.
\end{enumerate}
Then this proposition is basically stating that a fiber over some element can basically be defined as a ``shifting'' of a \textbf{representative}\footnote{A \textit{representative} is an element of a equivalence class used to \textit{represent} all the elements in that equivalence class.} of that fiber by the kernel set. An easy example of this would be some homomorphism $\varphi: \Z \rightarrow \Z/n\Z$, which would have $1, 1 \pm n, 1 \pm 2n, \dots$ as the fiber for the element $1 \in \Z/n\Z$, or that the fiber of 1 is just any preimage of 1 under $\varphi$ shifted by some $kn, k \in \Z$, as $kn \equiv 0 \pmod{n}$, where 0 is the identity representative in the additive group. \\ \\
\textbf{Definition - Left and Right Cosets}: For any $N \leq G$ and any $g \in G$, the left and right cosets of $N$ in $G$ are defined as $$gN = \{gn | n \in N\} \text{ and } Ng = \{ng | n \in N\},$$ respectively. An element of a coset is called a \textit{representative} for the coset. \\ \\
For additive groups we may instead write $g + N$ or $N + g$. \\ \\
\textbf{Theorem 3.3}: Let $G$ be a group and let $K$ be the kernel of some homomorphism from $G$ to another group. Then the set whose elements are the left cosets of $K$ in $G$ with operation defined by $$uK \circ vK = (uv)K$$ forms a group $G/K$. This statement also holds for right coset. \\ \\
In simpler terms, theorem 3 is essentially stating that modding out by the kernel is equivalent to reducing the group to left (or right) cosets of it's kernel with the operation defined above. \\ \\
\textbf{Proposition 3.4}: Let $N$ be any subgroup of the group $G$. The set of left cosets of $N$ in $G$ form a partition of $G$. Furthermore, for all $u, v \in G, uN = vN$ if and only if $v^{-1}u \in N$ and in particular, $uN = vN$ if and only if $u$ and $v$ are representatives of the same coset. \\ \\
\textbf{Proposition 3.5}: Let $G$ be a group and let $N$ be a subgroup of $G$. \begin{enumerate}
    \item The operation on the set of left cosets of $N$ in $G$ described by $$uN \cdot vN = (uv)N$$ is well defined iff $gng^{-1} \in N$ for all $g \in G$ and $n \in N$.
    \item If the above operation is well defined, then it makes the set of left cosets of $N$ in $G$ into a group. In particular the identity of this group is the coset $1N$ and the inverse of $gN$ is the coset $g^{-1}N$, i.e., $(gN)^{-1} = g^{-1}N$.
\end{enumerate} This proposition is essentially an extension of theorem 3 (in that $G/K$ forms a group) to all subgroups $N$ rather than just the kernel. \\ \\
\textbf{Definition - Conjugate, Normal}: The element $gng^{-1}$ is called the \textit{conjugate of $n \in N$ by} $g$. The set $gNg^{-1} = \{gng^{-1} | n \in N\}$ is called the \textit{conjugate of $N$ by} $g$. The element $g$ is
said to \textit{normalize} $N$ if $gNg^{-1} = N$. A subgroup $N$ of a group $G$ is called \textit{normal} if every element of $G$ normalizes $N$, i.e., if $gNg^{-1} = N$ for all $g \in G$. If $N$ is a normal subgroup of $G$ we shall write $N \trianglelefteq G$. It is important to remember that normality is a embedding property, i.e. $N$ being normal depends on the group $G$ of which it is a subgroup. \\ \\
\textbf{Theorem 6}: Let $N$ be a subgroup of the group $G$. The following are equivalent: \begin{enumerate}
    \item $N \trianglelefteq G$,
    \item $N_G(N) = G$ (recall $N_G(N)$ is the normalizer of $N$ in $G$),
    \item $gN = Ng$, for all $g \in G$,
    \item the operation on left cosets of $N$ in $G$ described in proposition 5 makes the set of left cosets into a group,
    \item $gNg^{-1} \subseteq N$ for all $g \in G$.
\end{enumerate} $ $ \\
If a subgroup $H \leq G$ of some order is the unique subgroup of that order, then $H \trianglelefteq G$. \\ \\
\textbf{Proposition 3.7}: A subgroup $N$ of the group $G$ is normal if and only if it is the kernel of some homomorphism. \\ \\
For $N \trianglelefteq G$, $gN = N$ iff $g \in N$. \\ \\
\textbf{Definition - Natural Projection, Complete Preimage}: Let $N \trianglelefteq G$. The homomorphism $\pi: G \rightarrow G/N$ defined by $\pi(g) = gN$ is called the \textit{natural projection} (homomorphism) of $G$ onto $G/N$. If $\overline{H} \leq G/N$ is a subgroup of $G/N$, the \textit{complete preimage} of $\overline{H}$ in $G$ is the preimage of $\overline{H}$ under the natural projection homomorphism. \\ \\
Then given $N \trianglelefteq G$, $\ker{\pi} = N$. \\ \\
Quotient groups of a cyclic group are cyclic. \\ \\
\textbf{Theorem 3.8 - Lagrange's Theorem}: If $G$ is a finite group and $H$ is a subgroup of $G$, then the order of $H$ divides the order of $G$ and the number of left cosets of $H$ in $G$ is $\mathlarger{\frac{|G|}{|H|}}$. \\ \\
\textbf{Definition - Index}: If $G$ is a group and $H \leq G$, the number of left cosets of $H$ in $G$ is called the index of $H$ in $G$ and is denoted by $|G:H|$. \\ \\
In the case of finite groups $|G:H| = |G|/|H|$. \\ \\
\textbf{Corollary 3.9}: If $G$ is a finite group and $x \in G$, then the order of $x$ divides the order of $G$. In particular, $x^{|G|} = 1_G$, for all $x \in G$. \\ \\
\textbf{Corollary 3.10}: If $G$ is of prime order $p$, then $G$ is cyclic and $G \cong Z_p$. \\ \\
\textbf{Theorem 3.11/Proposition 3.21 - Cauchy's Theorem}: If $G$ is a finite group and $p$ is a prime dividing $|G|$, then $G$ has an element of order $p$. \\ \\
\textbf{Theorem 3.12 - Sylow}: If $G$ is a finite group of order $p^\alpha m$, where $p$ is a prime and $p \nmid m$, then $G$ has a subgroup of order $p^\alpha.$ \\ \\
\textbf{Definition - Multiplication of Subgroups}: Let $H, K$ be subgroups of a group and define $$HK = \{hk | h \in H, k \in K\}.$$ \\
\textbf{Proposition 3.13}: If $H, K$ are finite subgroups of a group then $$|HK| = \frac{|H||K|}{|H \cap K|}.$$ \\
\textbf{Proposition 3.14}: If $H, K$ are subgroups of a group, $HK$ is a subgroup iff $HK = KH$. \\ \\
One should be careful not to misinterpret 3.14 to mean that the subgroup $HK$ is Abelian, rather that $hk = k'h'$. \\ \\
\textbf{Corollary 3.15}: If $H, K$ are subgroups of $G$ and $H \leq N_G(K)$, then $HK$ is a subgroup of $G$. In particular, if $K \trianglelefteq G$, then $HK \leq G$ ($HK$ is a subgroup) for any $H \leq G$. \\ \\
\textbf{Definition - Normalizes}: If $A$ is any subset of $N_G(K)$ (or $C_G(K)$), we shall say that $A$ \textit{normalizes} $K$ (or \textit{centralizes}, respectively). \\ \\
\textbf{Theorem 3.16 - The First Isomorphism Theorem}: If $\varphi : G \rightarrow H$ is a homomorphism of groups, then $\ker{\varphi} \trianglelefteq G$ and $G/\ker{\varphi} \cong \varphi(G)$. \\ \\
Another way to interpret theorem 3.16 is that for any homomorphism $\varphi: G \rightarrow H$, there exists a injective group homomorphism $\overline{\varphi}: G/\ker{\varphi} \rightarrow H$. \\ \\
\textbf{Corollary 3.17}: Let $\varphi : G \rightarrow H$ is a homomorphism of groups. \begin{enumerate}
    \item $\varphi$ is injective iff $\ker{\varphi} = 1$.
    \item $|G : \ker{\varphi}| = |\varphi(G)|$.
\end{enumerate} $ $ \\
\textbf{Theorem 3.18 - The Second/Diamond Isomorphism Theorem}: Let $G$ be a group and $A, B \leq G$ and assume $A \leq N_G(B)$. Then $AB$ is a subgroup of $G$, $B \trianglelefteq AB, A \cap B \trianglelefteq A, AB/B \cong A/A \cap B$. \\ \\
\textbf{Theorem 3.19 - The Third Isomorphism Theorem}: Let $G$ be a group and let $H, K$ be normal subgroups of $G$ with $H \leq K$. Then $K/H \trianglelefteq G/H$ and $$(G/H)/(K/H) \cong G/K.$$
\textbf{Theorem 3.20 - The Fourth/Lattice Isomorphism Theorem}: Let $G$ be a group and let $N$ be a normal subgroup of $G$. Then there is a bijection from the set of subgroups $A$ of $G$ which contain $N$ onto the set of subgroups $\overline{A} = A/N$ of $G/N$. In particular, every subgroup of $\overline{G}$ is of the form $A/N$ for some subgroup $A$ of $G$ containing $N$ (namely, it's preimage in $G$ under the projection homomorphism from $G$ to $G/N$). This bijection has the following properties: for all $A, B \leq G$ with $N \leq A, B$, \begin{enumerate}
    \item $A \leq B$ iff $\overline{A} \leq \overline{B}$,
    \item if $A \leq B$, then $|B : A| = |\overline{B} : \overline{A}|$,
    \item $\overline{\langle A, B \rangle} = \langle \overline{A}, \overline{B} \rangle$,
    \item $\overline{A \cap B} = \overline{A} \cap \overline{B}$,
    \item $A \trianglelefteq G$ iff $\overline{A} \trianglelefteq \overline{G}$.
\end{enumerate} $ $ \\
\textbf{Definition - Simple}: A (finite or infinite) group $G$ is called \textit{simple} if $|G| > 1$ and the only normal subgroups of $G$ are $1$ and $G$. \\ \\
If $|G|$ is prime, then it's only subgroups are 1 and $G$, and is thus simple. In fact, every simple Abelian group is isomorphic to $Z_p$, for some prime $p$. \\ \\
\textbf{Proposition 3.21}: If $G$ is a finite abelian group and $p$ is a prime dividing $|G|$, then $G$ contains an element of order $p$. \\ \\
\textbf{Definition - Composition Series}: In a group $G$ a sequence of subgroups $$1 = N_0 \leq N_1 \leq \dots \leq N_{k - 1} \leq N_k = G$$ is called a \textit{composition series} if $N_i \trianglelefteq N_{i + 1}$ and $N_{i + 1}/N_i$ is a simple group, $0 \leq i \leq k - 1$. If the above sequence is a composition series, the quotient groups $N_{i + 1}/N_i$ are called \textit{composition factors} of $G$. \\ \\
\textbf{Theorem 3.22 - Jordan-Hölder Theorem}: Let $G$ be a finite group with $G \neq 1$. Then \begin{enumerate}
    \item $G$ has a composition series and
    \item The composition factors in a composition series are unique, namely, if $1 = N_0 \leq N_1 \leq \dots \leq N_r = G$ and $1 = M_0 \leq M_1 \leq \dots \leq M_s = G$ are two composition series for $G$, then $r = s$ and there is some permutation $\pi$ of $\{1, 2, \dots, r\}$ such that $$M_{\pi(i)}/M_{\pi(i) - 1} \cong N_i/N_{i - 1}, 1 \leq i \leq r.$$
\end{enumerate} $ $ \\
In other words, a composition series of a finite group $G$ is essentially a factorization of $G$. Unlike factorizing integers, however, the series itself need not be unique, but the number of composition factors and their isomorphism types are uniquely determined. \\ \\
\textbf{The Hölder Program}: \begin{enumerate}
    \item Classify all finite simple groups.
    \item Find all ways of ``putting simple groups together'' to form other groups (sometimes called the \textit{Extension Problem})
\end{enumerate} $ $ \\
\textbf{Definition - Transposition}: A 2-cycle is called a \textit{transposition}. \\ \\
Every element of $S_n$ can be written as a product of transpositions, though not uniquely. \\ \\
\textbf{Definition - Sign of a Permutation}: Define $\Delta = \prod_{1 \leq i < j \leq n} (x_i - x_j)$ and $\sigma(\Delta) = \prod_{1 \leq i < j \leq n} (x_{\sigma(i)} - x_{\sigma(j)})$. Then it is clear that $\sigma(\Delta) = \pm \Delta$ for all $\sigma \in S_n$. Define $\epsilon(\sigma)$, the \textit{sign} of $\sigma$, by $$\epsilon(\sigma) = \begin{cases}
    +1, \text{ if } \sigma(\Delta) = \Delta \\
    -1, \text{ if } \sigma(\Delta) = -\Delta
\end{cases}.$$ We say that $\sigma$ is an \textit{even permutation} if $\epsilon(\sigma) = +1$ or \textit{odd permutation} if $\epsilon(\sigma) = -1$. \\ \\
\textbf{Proposition 3.23}: The map $\epsilon : S_n \rightarrow \{\pm 1\}$ is a homomorphism (where $\{\pm 1\}$ is a multiplicative version of the cyclic group of order 2). This proposition basically just tells you that composing two even/odd permutations results in an even permutation, and composing an even and an odd permutation results in an odd permutation. \\ \\
\textbf{Proposition 3.24}: Transpositions are all odd permutations and $\epsilon$ is a surjective homomorphism. \\ \\
\textbf{Definition - Alternating Group}: The \textit{alternating group of degree} $n$, denoted by $A_n$, is the kernel of the homomorphism $\epsilon$ (i.e., the set of even permutations). \\ \\
$|A_n| = \frac{n!}{2}$. \\ \\
Using the fact that an $m$-cycle can be written as a product of $m - 1$ transpositions, an $m$-cycle is an odd permutation iff $m$ is even. \\ \\
\textbf{Proposition 3.25}: The permutation $\sigma$ is odd iff the number of cycles of even length in its cycle decomposition is odd.
\subsection*{Chapter 4 - Group Actions}
\textbf{Definition - Group Action}: A \textit{group action} of a group $G$ on a set $A$ is a map from $G \times A \rightarrow A$ satisfying the following properties: \begin{enumerate}
    \item \textit{Compatibility}: $g_1 \cdot (g_2 \cdot a) = (g_1g_2) \cdot a$, for all $g_1, g_2 \in G, a \in A$,
    \item \textit{Identity}: $1 \cdot a = a$, for all $a \in A$
\end{enumerate} $ $ \\
\textbf{Definition - Permutation Representation}: Define $\sigma_g: A \rightarrow A$ by $\sigma_g: a \mapsto g \cdot a$ and $\varphi: G \rightarrow S_A$ by $\varphi(g) = \sigma_g$. $\varphi$ is called the \textit{permutation representation} associated to the given action. \\ \\
\textbf{Definition - Stabilizer}: If a group $G$ is acting on a set $A$, for a fixed element $a \in A$, we define the \textit{stabilizer} of $a$ in $G$ as $$G_a = \{g \in G | g \cdot a = a\}.$$ The stabilizer of any element $a$ forms a subgroup of $G$. \\ \\
\textbf{Definition - Kernel of a Group Action}: The \textit{kernel} of an action $G$ on $A$ is defined as $$\ker(G) = \{g \in G| g \cdot a = a, \forall a \in A\} = \bigcap_{a \in A} G_a.$$ \\
\textbf{Definition - Faithful}: If $G$ acts on $A$ and each element of $G$ induce different permutations of $A$, then the action is said to be \textit{faithful}, i.e. injective. An action is faithful if it's kernel is the identity. \\ \\
An action of $G$ on $A$ can be equivalently viewed as a faithful action of $G/\ker{\varphi}$ on $A$. \\ \\
\textbf{Proposition 4.1}: For any group $G$ and any nonempty set $A$ there is a bijection between the actions of $G$ on $A$ and the homomorphisms of $G$ into $S_A$. \\ \\
4.1 can be realized by defining an action $G$ on $A$ by $g \cdot a = \varphi(g)(a)$, where $\varphi$ is the permutation representation of the action $G$. \\ \\
\textbf{Definition - Induce}: If $G$ is a group, a \textit{permutation representation} of $G$ is any homomorphism of $G$ into the symmetric group $S_A$ for some nonempty set $A$. We shall say a given action of $G$ on $A$ \textit{affords} or \textit{induces} the associated permutation representation of $G$. \\ \\
\textbf{Proposition 4.2}: Let $G$ be a group acting on the nonempty set $A$. The relation on $A$ defined by $$a \sim b \text{ iff } a = g \cdot b \text{ for some } g \in G$$ is an equivalence relation. For each $a \in A$, the number of elements in the equivalence class containing $a$ is $|G : G_a|$, the index of the stabilizer of $a$. \\ \\
\textbf{Definition - Orbit, Transitive}: Let $G$ be a group acting on the nonempty set $A$. \begin{enumerate}
    \item The equivalence class $\{g \cdot a | g \in G\}$ is called the \textit{orbit} of $G$ containing $a$.
    \item The action of $G$ on $A$ is called \textit{transitive} if there is only one orbit, i.e., given any two elements $a, b \in A$ there is some $g \in G$ such that $a = g \cdot b$.
\end{enumerate} $ $ \\
Subgroups of symmetric groups are called \textit{permutation groups}. \\ \\
Any group action of a group $G$ acting on itself can be given a permutation representation $\sigma_g \in S_n$, for every $g \in G,$ by labeling the elements of $G$ as $\{g_1, g_2, \dots, g_n\}$, where the identity permutation corresponds to $g = 1$. The same can be done on left cosets of some subgroup $H \leq G$. This form of representing a group action is useful because $\sigma_{sr^2} = \sigma_s \sigma_r^2$. \\ \\
The action of a group on itself by left multiplication is always transitive and faithful, and the stabilizer of any point is the identity subgroup. \\ \\
\textbf{Theorem 4.3}:  Let $G$ be a group, let $H$ be a subgroup of $G$ and let $G$ act by left multiplication on the set $A$ of left cosets of $H$ in $G$. Let $\pi_H$ be the associated permutation representation afforded by this action. Then \begin{enumerate}
    \item $G$ acts transitively on $A$
    \item the stabilizer in $G$ of the point $1H \in A$ is the subgroup $H$
    \item  the kernel of the action (i.e., the kernel of $\pi_H$) is $\cap_{x \in G} xHx^{-1}$, and $\ker{\pi_H}$ is the largest normal subgroup of $G$ contained in $H$.
\end{enumerate} $ $ \\
\textbf{Corollary 4.4 - Cayley's Theorem}: Every group is isomorphic to a subgroup of some symmetric group. If $G$ is a group of order $n$, then $G$ is isomorphic to a subgroup of $S_n$ (permutation group). \\ \\
\textbf{Corollary 4.5}: If $G$ is a finite group of order $n$ and $p$ is the smallest prime dividing $n$, then any subgroup of index $p$ is normal. \\ \\
A group acting on itself by conjugating is a group $G$ acting on a set $G$ by $$g \cdot a = gag^{-1}, \text{ for all } g \in G, a \in G$$ where $gag^{-1}$ is computed in the group $G$. \\ \\
\textbf{Definition - Conjugate, Conjugacy Classes}: Two elements $a, b \in G$ are said to be \textit{conjugate} in $G$ if there is some $g \in G$ such that $b = gag^{-1}$ (i.e., if and only if they are in the same orbit of $G$ acting on itself by conjugation). The orbits of $G$ acting on itself by conjugation are called the \textit{conjugacy classes} of $G$. \\ \\
$G$ acting on $\mathcal{P}(G)$ is called $G$ acting on it's subsets. \\ \\
\textbf{Definition - Conjugate In $G$}: Two subsets $S$ and $T$ of $G$ are said to be \textit{conjugate in} $G$ if there is some $g \in G$ such that $T = gsg^{-1}$ (i.e., if and only if they are in the same orbit of $G$ acting on its subsets by conjugation). \\ \\
$\{x\}$ is a conjugacy class of size 1 iff $x \in Z(G)$. \\ \\
\textbf{Proposition 4.6}: The number of conjugates of a subset $S$ in a group $G$ is the index of the normalizer of $S$, $|G : N_G(S)|$. In particular, the number of conjugates of an element $s$ of $G$ is the index of the centralizer of $s$, $|G : C_G(s)|$. \\ \\
\textbf{Theorem 4.7 - The Class Equation}: Let $G$ be a finite group and let $g_1 , g_2 , \dots, g_r$ be representatives of the distinct conjugacy classes of $G$ not contained in the center $Z(G)$ of $G$. Then $$|G| = |Z(G)| + \sum_{i = 1}^r |G : C_G(g_i)|.$$ \\
\textbf{Theorem 4.8}: If $p$ is a prime and $P$ is a group of prime power order $p^a$ for some $a \geq 1$, then $P$ has a nontrivial center: $Z(P) \neq 1$. \\ \\
\textbf{Corollary 4.9}: If $|P| = p^2$ for some prime $p$, then $P$ is Abelian. More precisely, $P$ is isomorphic to either $Z_{p^2}$ or $Z_P \times Z_P$. \\ \\
\textbf{Proposition 4.10}: Let $\sigma, \tau$ be elements of the symmetric group $S_n$ and suppose $\sigma$ has cycle decomposition $$(a_1 a_2 \dots a_{k_1})(b_1 b_2 \dots b_{k_2}) \dots.$$ Then $\tau \sigma \tau^{-1}$ has cycle decomposition $$(\tau(a_1) \tau(a_2) \dots \tau(a_{k_1}))(\tau(b_1) \tau(b_2) \dots \tau(b_{k_2})) \dots,$$ that is, $\tau \sigma \tau^{-1}$ is obtained by replacing each entry $i$ in the cycle decomposition for $\sigma$ by the entry $\tau(i)$. \\ \\
\textbf{Definition - Cycle Type, Partition}: \begin{enumerate}
    \item If $\sigma \in S_n$ is the product of disjoint cycles of lengths $n_1, n_2, . .. , n_r$ with $n_1 \leq n_2 \leq \dots \leq n_r$ (including its 1-cycles) then the integers $n_1, n_2, . .. , n_r$ are called the \textit{cycle type} of $\sigma$. 
    \item If $n \in \Z^+$, a \textit{partition} of $n$ is any non-decreasing sequence of positive integers whose sum is $n$. 
\end{enumerate} $ $ \\
\textbf{Proposition 4.11}: Two elements of $S_n$ are conjugate in $S_n$ if and only if they have the same cycle type. The number of conjugacy classes of $S_n$ equals the number of partitions of $n$. \\ \\
For an $m$-cycle $\sigma \in S_n$, $|C_{S_n}(\sigma)| = m \cdot (n - m)!$, as $$C_{S_n}(\sigma) = \{\sigma^i \tau| 0 \leq i < m, \tau \in S_{n - m}\},$$ where $S_{n - m}$ denotes the subgroup of $S_n$ which fixes all the indices which appear in the $m$-cycle $\sigma$. \\ \\
\textbf{Theorem 4.12}: $A_5$ is a simple group. \\ \\
Define the right conjugation of $a$ by $g$ as $$a^g = g^{-1}ag, \text{ for all } a, g \in G.$$ \\
\textbf{Definition - Corresponding Group Actions}: \textit{Corresponding group actions} are left and right group actions which do the same thing on different sides of the value they are acting on. In other words, $g$ acts on the left the same way that $g^{-1}$ acts on the right. Orbits are the same for left and right actions. \\ \\
\textbf{Definition - Automorphism}: Let $G$ be a group. An isomorphism from $G$ onto itself is called an automorphism of $G$. The set of all \textit{automorphisms} of $G$ is denoted by $\aut(G)$. \\ \\
Automorphisms map subgroups to subgroups, as a result of being a homomorphisms. \\ \\ 
$\aut(G)$ forms a group. Note that automorphisms of $G$ are essentially just the elements of $G$ up to permutation, so $\aut(G) \leq S_G$. \\ \\
\textbf{Proposition 4.13}: Let $H$ be a normal subgroup of the group $G$. Then $G$ acts by conjugation on $H$ as automorphisms of $H$. More specifically, the action of $G$ on $H$ by conjugation is defined for each $g \in G$ by $$\varphi_g: h \mapsto ghg^{-1}, \text{ for each } h \in H.$$ For each $g \in G$, conjugation by $g$ is an automorphism of $H$. The permutation representation afforded by this action is a homomorphism of $G$ into $\aut(H)$ with kernel $C_G(H)$. In particular, $G/C_G(H)$ is isomorphic to a subgroup of $\aut(H)$. \\ \\
Note about 4.13: Then the permutation representation of these automorphisms $\varphi_g$ defined for each $g \in G$ is homomorphism $\psi: G \rightarrow S_H$ defined by $\psi(g) = \varphi_g.$ \\ \\
Proposition 13 shows that a group acts by conjugation on a normal subgroup as structure preserving permutations, i.e., as automorphisms. \\ \\
\textbf{Corollary 4.14}: If $K$ is any subgroup (not necessarily normal) of the group $G$ and $g \in G$, then $K \cong gKg^{-1}$. Conjugate elements and conjugate subgroups have the same order. \\ \\
\textbf{Corollary 4.15}: For any subgroup $H$ of a group $G$, the quotient group $N_G(H)/C_G(H)$ is isomorphic to a subgroup of $\aut(H)$. In particular, $G/Z(G)$ is isomorphic to a subgroup of $\aut(G)$. \\ \\
\textbf{Definition - Inner Automorphism}: Let $G$ be a group and let $g \in G$. Conjugation by $g$ is called an \textit{inner automorphism} of $G$ and the subgroup of $\aut(G)$ consisting of all inner automorphisms is denoted by $\inn(G)$. \\ \\
The ``subgroup of $\aut(G)$'' referenced in corollary 4.15 (both of them) is $\inn(G)$. \\ \\
\textbf{Definition - Characteristic}: A subgroup $H$ of a group $G$ is called \textit{characteristic in} $G$, denoted $H \Char G$, if every automorphism of $G$ maps $H$ to itself, i.e., $\sigma(H) = H$ for all $\sigma \in \aut(G)$. \\ \\
\textbf{Results Concerning Characteristic Subgroups}: \begin{enumerate}
    \item characteristic subgroups are normal,
    \item if $H$ is the unique subgroup of $G$ of a given order, then $H$ is characteristic in $G$, and
    \item if $K \Char H$ and $H \trianglelefteq G$, then $K \trianglelefteq G$ (so although ``normality'' is not a transitive property (i.e., a normal subgroup of a normal subgroup need not be normal, a characteristic subgroup of a normal subgroup is normal).
\end{enumerate} Then characteristic is a stronger condition than normal. \\ \\
\textbf{Proposition 4.16}: The automorphism group of the cyclic group of order $n$ is isomorphic to $(\Z/n\Z)^\times$, an abelian group of order $\varphi(n)$ (where $\varphi$ is Euler's function). \\ \\
\textbf{Proposition 4.17 (Inc. Elementary Abelian Definition)}: \begin{enumerate}
    \item If $p$ is an odd prime and $n \in \Z^+$, then the automorphism group of the cyclic group of order $p$ is cyclic of order $p - 1$. More generally, the automorphism group of the cyclic group of order $p^n$ is cyclic of order $p^{n - 1}(p - 1)$. 
    \item For all $n \geq 3$ the automorphism group of the cyclic group of order $2^n$ is isomorphic to $Z_2 \times Z_{2^{n - 2}}$, and in particular is not cyclic but has a cyclic subgroup of index $2$. 
    \item Let $p$ be a prime and let $V$ be an abelian group (written additively) with the property that $pv = 0$ for all $v \in V$. If $|V| = p^n$, then $V$ is an $n$-dimensional vector space over the field $\F_p = \Z/p\Z$ called the \textit{elementary abelian group of order $p^n$}. The automorphisms of $V$ are precisely the non-singular linear transformations from $V$ to itself, that is $$\aut(V) \cong GL(V) \cong GL_n(\F_p),$$ where $GL(V)$ is the group of all invertible (non-singular) linear transformations from $V$ to itself.
    \item For all $n \neq 6$ we have $\aut(S_n) = \inn(S_n) \cong S_n$. For $n = 6$ we have $|\aut(S_6) : \inn(S_6)| = 2$.
    \item $\aut(D_8) \cong D_8$ and $\aut(Q_8) \cong S_4$
\end{enumerate} $ $ \\
The Klein 4-group $V_4$ is called the elementary abelian group of order 4. \\ \\
For any prime $p$, the elementary abelian group of order $p^2$ is $Z_p \times Z_p.$  \\ \\
\textbf{Definition - $p$-Groups, Sylow $p$-Subgroup}: Let $G$ be a group and let $p$ be a prime. \begin{enumerate}
    \item A group of order $p^a$ for some $a \geq 1$ is called a \textit{$p$-group}. Subgroups of $G$ which are $p$-groups are called \textit{$p$-subgroups}.
    \item If $G$ is a group of order $p^am$, where $p \nmid m$, then a subgroup of order $p^a$ is called a \textit{Sylow $p$-subgroup of $G$}.
    \item The set of Sylow $p$-subgroups of $G$ will be denoted by $\syl_p(G)$ and the number of Sylow $p$-subgroups of $G$ will be denoted by $n_p(G)$ (or just $n_p$ when $G$ is clear from the context).
\end{enumerate} $ $ \\
\textbf{Theorem 4.18 - Sylow's Theorem}: Let $G$ be a group of order $p^am$, where $p$ is a prime not dividing $m$. \begin{enumerate}
    \item Sylow $p$-subgroups of $G$ exist, i.e., $\syl_p(G) \neq 0$.
    \item If $P$ is a Sylow $p$-subgroup of $G$ and $Q$ is any $p$-subgroup of $G$, then there exists $g \in G$ such that $Q \leq gPg^{-1}$, i.e., $Q$ is contained in some conjugate of $P$. In particular, any two Sylow $p$-subgroups of $G$ are conjugate in $G$.
    \item  The number of Sylow $p$-subgroups of $G$ is of the form $1 + kp$, i.e., $$n_p \equiv 1 \pmod{p}.$$ Further, $n_p$ is the index of the normalizer $N_G(P)$ in $G$ for any Sylow $p$-subgroup $P$, hence $n_p$ divides $m$.
\end{enumerate} $ $ \\
\textbf{Lemma 4.19}: Let $P \in \syl_p(G)$. If $Q$ is any $p$-subgroup of $G$, then $Q \cap N_G(P) = Q \cap P$. \\ \\
\textbf{Corollary 4.20}: Let $P$ be a Sylow $p$-subgroup of $G$. Then the following are equivalent: \begin{enumerate}
    \item $P$ is the unique Sylow $p$-subgroup of $G$, i.e., $n_p = 1$
    \item $P$ is normal in $G$
    \item $P$ is characteristic in $G$
    \item All subgroups generated by elements of $p$-power order are $p$-groups, i.e., if $X$ is any subset of $G$ such that $|x|$ is a power of $p$ for all $x \in X$, then $\langle X \rangle$ is a $p$-group. 
\end{enumerate} $ $ \\
If a subgroup $H \leq G$ has index 2, then $H$ is normal. \\ \\
\textbf{Proposition 4.21}: If $|G| = 60$ and $G$ has more than one Sylow 5-subgroup, then $G$ is simple. \\ \\
\textbf{Proposition 4.23}: If $G$ is a simple group of order $60$, then $G \cong A_5$.
\subsection*{5. Direct and Semi-direct Products and Abelian Group}
\textbf{Definition - Direct Product}: \begin{enumerate}
    \item The \textit{direct product} $G_1 \times G_2 \times \dots \times G_n$ of the groups $G_1, G_2, \dots, G_n$ with operations $\star_1, \star_2, \dots, \star_n$ respectively, is the set of $n$-tuples $(g_1, g_2, \dots, g_n)$ where $g_i \in G_i$ with operation defined component-wise: $$(g_1, g_2, \dots, g_n) \star (h_1, h_2, \dots, h_n) = (g_1 \star_1 h_1, g_2 \star_2 h_2, \dots, g_n \star_n h_n).$$
    \item Similarly, the \textit{direct product} $G_1 \times G_2 \times \dots$ of the groups $G_1, G_2, \dots$ with operations $\star_1, \star_2, \dots$ respectively, is the set of sequences $(g_1, g_2, \dots)$ where $g_i \in G_i$ with operation defined component-wise: $$(g_1, g_2, \dots) \star (h_1, h_2, \dots) = (g_1 \star_1 h_1, g_2 \star_2 h_2, \dots).$$
\end{enumerate} $ $ \\
\textbf{Proposition 5.1}: If $G_1, G_2 \dots, G_n$ are groups, their direct product is a group of order $|G_1||G_2| \dots |G_n|$ (if any $G_1$ is infinite, so is the direct product). \\ \\
\textbf{Proposition 5.2}: Let $G_1, G_2 \dots, G_n$ be groups and $G = G_1 \times \dots \times G_n$ be their direct product. \begin{enumerate}
    \item For each fixed $i$ the set of elements of $G$ which have the identity of $G_j$ in the $j$th position for all $j \neq i$ and arbitrary elements of $G_1$ in position $i$ is a subgroup of $G$ isomorphic to $G_i$: $$G_i \cong \{(1, \dots, 1, g_i, 1, \dots, 1) | g_i \in G_i\},$$ (here $g_i$ appears in the $i$th position and the subgroup on the right is often called the $i$th component or $i$th factor of $G$). If we identify $G_i$ with this subgroup, then $G_i \trianglelefteq G$ and $$G/G_i \cong G_1 \times \dots \times G_{i - 1} \times G_{i + 1} \times \dots \times G_n$$
    \item For each fixed $i$ define $\pi_i: G \rightarrow G_i$ by $$\pi_i(g_1, \dots, g_n) = g_i.$$ Then $\pi_i$ is a surjective homomorphism with \begin{align*}
        \ker{\pi_i} &= \{(g_1, \dots, g_{i - 1}, 1, g_{i + 1}, \dots, g_n)| g_j \in G_j \text{ for all } j \neq i\} \\
        &\cong G_1 \times \dots \times G_{i - 1} \times G_{i + 1} \times \dots \times G_n
    \end{align*}
    \item Under the identifications in part $(1)$, if $x \in G_i$ and $y \in G_j$ for some $i \neq j$, then $xy = yx$ (this idea is similar to commutativity of disjoint cycles).
\end{enumerate} $ $ \\
$E_{p^n} = Z_p \times Z_p \times \dots \times Z_p$ is the \textit{elementary abelian group} of order $p^n$. \\ \\
\textbf{Definition - Finitely Generated, Free Abelian Group of Rank $r$}: \begin{enumerate}
    \item A group $G$ is \textit{finitely generated} if there is a finite subset $A$ of $G$ such that $G = \langle A \rangle$.
    \item For each $r \in \Z$ with $r \geq 0$, let $\Z^r = \Z \times \dots \times \Z$ be the direct product of $r$ copies of the group $\Z$, where $\Z^0 = 1$. The group $\Z^r$ is called the \textit{free abelian group of rank $r$}.
\end{enumerate} $ $ \\
\textbf{Theorem 5.3 - Fundamental Theorem of Finitely Generated Abelian Groups}: Let $G$ be a finitely generated abelian group. Then \begin{enumerate}
    \item $$G \cong \Z^r \times Z_{n_1} \times \dots \times Z_{n_s},$$ for some integers $r, n_1, \dots, n_s$ satisfying the following conditions: \begin{enumerate}
        \item $r \geq 0$ and $n_j \geq 2$ for all $j$, and
        \item $n_{i + 1} | n_i$ for $1 \leq i \leq s - 1$
    \end{enumerate}
    \item the expression in $(1)$ is unique: if $G \cong \Z^t \times Z_{m_1} \times \dots \times Z_{m_u}$, where $t$ and $m_1, \dots, m_u$ satisfy (a) and (b) (i.e., $t \geq 0, m_j \geq 2$ for all $j$, and $m_{i + 1} | m_i$ for $1 \leq i \leq u - 1$), then $t = r, u = s$ and $m_i = n_i$ for all $i$.
\end{enumerate} $ $ \\
\textbf{Definition - Free Rank/Betti Number, Invariant Factor (Decomposition), Type}: The integer $r$ in Theorem 3 is called the \textit{free rank} or \textit{Betti number} of $G$ and the integers $n_1, n_2, \dots, n_s$ are called the \textit{invariant factors} of $G$. The description of $G$ in Theorem 3(1) is called the \textit{invariant factor decomposition} of $G$. If $G$ is a finite abelian group, satisfying (b) above, then $G$ is said to be of \textit{type} $(n_1, n_2, \dots, n_s)$. \\ \\
Thus a finitely generated abelian group is a finite group if and only if its free rank is zero. \\ \\
\textbf{Some Observations}: \begin{enumerate}
    \item $n_1 \geq n_2 \geq \dots \geq n_s$ as a result of the divisibility condition.
    \item Every prime divisor of $n$ must divide the first invariant factor $n_1$.
    \item One immediate consequence is that if $n$ is a product of distinct primes (square-free), then $n | n_1$, and thus $n = n_1$ and there is only one possible list of invariant factors for an abelian group of order $n$, namely just the length 1 list $n = n_1$ itself.
\end{enumerate} $ $ \\
\textbf{Corollary 5.4}: If $n$ is the product of distinct primes, then up to isomorphism the only abelian group of order $n$ is the cyclic group of order $n$, $Z_n$. This is an immediate consequence of part 3 from the above observations. \\ \\
\textbf{Theorem 5.5}: Let $G$ be an abelian group of order $n > 1$ and let the unique factorization of $n$ into distinct prime powers be $$n = p_1^{\alpha_1} p_2^{\alpha_2} \dots p_n^{\alpha_n}.$$ Then \begin{enumerate}
    \item $G \cong A_1 \times A_2 \times \dots \times A_k,$ where $|A_i| = p_i^{\alpha_i},$ or $A_i$ is the Sylow $p_i$-subgroup of $G$.
    \item For each $A \in \{A_1, A_2, \dots, A_k\}$ with $|A| = p^\alpha$, $$A \cong Z_{p^{\beta_1}} \times  Z_{p^{\beta_2}} \times \dots \times Z_{p^{\beta_t}}$$ with $\beta_1 \geq \beta_2 \geq \dots \geq \beta_t \geq 1$ and $\beta_1 + \beta_2 + \dots + \beta_t = \alpha$. In other words, the $\beta_j$'s form a partition of $\alpha$.
    \item the decomposition in (1) and (2) is unique, i.e., if $G \cong B_1 \times B_2 \times \dots \times B_m$, with $|B_i| = p_i^{\alpha_i}$ for all $i$, then $B_i \cong A_i$ and $B_i$ and $A_i$ have the same invariant factors. 
\end{enumerate} $ $ \\
Note that since $G$ is assumed to be abelian above, each Sylow $p_i$-subgroup $A_i$ is normal, and thus unique, in $G$. \\ \\
\textbf{Definition - Elementary Divisor (Decomposition)}: The integers $p^{\beta_j}$ described in the preceding theorem are called the \textit{elementary divisors} of $G$. The description of $G$ in Theorem 5(1) and 5(2) is called the \textit{elementary divisor decomposition} of $G$. \\ \\
The elementary divisors of $G$ are not invariant factors of $G$, rather they are invariant factors of subgroups ($p_i^{\alpha_i}$) of $G$. \\ \\
\textbf{Proposition 5.6}: Let $m, n \in \Z^+$. \begin{enumerate}
    \item $Z_m \times Z_n \cong Z_{mn}$ iff the GCD $(m, n) = 1$.
    \item If $n = p_1^{\alpha_1} p_2^{\alpha_2} \dots p_k^{\alpha_k}$, then $Z_n \cong Z_{p_1^{\alpha_1}} \times Z_{p_2^{\alpha_2}} \times \dots \times Z_{p_k^{\alpha_k}}.$
\end{enumerate} $ $ \\
\textbf{Definition - Rank, Exponent}: \begin{enumerate}
    \item If $G$ is a finite abelian group of type $(n_1, n_2, \dots, n_t)$, the integer $t$ is called the \textit{rank} of $G$ (the free rank of $G$ is 0 so there will be no confusion).
    \item If $G$ is any group, the \textit{exponent} of $G$ is the smallest positive integer $n$ such that $x^n = 1$ for all $x \in G$ ((if no such integer exists the exponent of $G$ is $\infty$).
\end{enumerate} $ $ \\
\textbf{Definition - Commutator, Commutator Subgroup}: Let $G$ be a group, let $x, y \in G$ and let $A, B$ be nonempty subsets of $G$. \begin{enumerate}
    \item Define $[x, y] = x^{-1}y^{-1}xy$ to be the \textit{commutator} of $x$ and $y$.
    \item Define $[A, B] = \langle [a, b] | a \in A, b \in B \rangle$, the group generated by commutators of elements of $A$ and $B$.
    \item Define $G' = \langle [x, y] | x, y \in G \rangle$, the subgroup of $G$ generated by commutators of elements from $G$, called the \textit{commutator subgroup of $G$}.
\end{enumerate} $ $ \\
Thus $x, y \in G$ commute iff $[x, y] = 1$. \\ \\
\textbf{Proposition 5.7}: Let $G$ be a group, let $x, y \in G$ and let $H \leq G$. Then \begin{enumerate}
    \item $xy = yx[x, y]$ (in particular, $xy = yx$ iff $[x, y] = 1$).
    \item $H \trianglelefteq G$ iff $[H, G] \leq H$.
    \item $\sigma[x, y] = [\sigma(x), \sigma(y)]$ for any automorphism $\sigma$ of $G$, $G' \Char G$ and $G/G'$ is abelian.
    \item $G/G'$ is the largest abelian quotient of $G$ in the sense that if $H \trianglelefteq G$ and $G/H$ is abelian, then $G' \leq H$. Conversely, if $G' \leq H$, then $H \trianglelefteq G$ and $G/H$ is abelian. 
    \item If $\varphi: G \rightarrow A$ is any homomorphism of $G$ into an abelian group $A$, then $\varphi$ factors through $G'$ i.e., $G' \leq \ker{\varphi}$ and the following diagram commutes: \begin{figure}[H]
\begin{center}
\includegraphics[scale=0.4]{prop5.7.png}
\end{center}
\end{figure}
\end{enumerate} $ $ \\
\textbf{Proposition 5.8}: Let $H$ and $K$ be subgroups of the group $G$. The number of distinct ways of writing each element of the set $HK$ in the form $hk$, for some $h \in H$ and $k \in K$ is $|H \cap K|$. In particular, if $H \cap K = 1$, then each element of $HK$ can be written uniquely as a product $hk$, for some $h \in H$ and $k \in K$. \\ \\
\textbf{Theorem 5.9}: Suppose $G$ is a group with subgroups $H$ and $K$ such that \begin{enumerate}
    \item $H$ and $K$ are normal in $G$, and
    \item $H \cap K = 1$.
\end{enumerate} Then $HK \cong H \times K.$ \\ \\
\textbf{Definition - Internal/External Direct Product}: If $G$ is a group and $H$ and $K$ are normal subgroups of $G$ with $H \cap K = 1$, we call $HK$ the \textit{internal direct product} of $H$ and $K$. We shall (when emphasis is called
for) call $H x K$ the \textit{external direct product} of $H$ and $K$. \\ \\
\textbf{Theorem 5.10}: Let $H$ and $K$ be groups and let $\varphi$ be a homomorphism from $K$ into $\aut(H)$. Let $\cdot$ denote the (left) action of $K$ on $H$ determined by $\varphi$· Let $G$ be the set of ordered pairs $(h, k)$ with $h \in H$ and $k \in K$ and define the following multiplication on $G$: $$(h_1, k_1)(h_2, k_2) = (h_1 k_1 \cdot h_2, k_1 k_2).$$ \begin{enumerate}
    \item This multiplication makes $G$ into a group of order $|G| = |H||K|$.
    \item The sets $\{(h, 1) | h \in H\}$ and $\{(1, k) | k \in K\}$ are subgroups of $G$ and the maps $h \mapsto (h, 1)$ for $h \in H$ and $k \mapsto (1 , k)$ for $k \in K$ are isomorphisms of these subgroups with the groups $H$ and $K$ respectively: $$H \cong \{(h, 1) | h \in H\} \text{ and } K \cong \{(1, k) | k \in K\}.$$
\end{enumerate} Identifying $H$ and $K$ with their isomorphic copies in $G$ described in (2) we have \begin{enumerate}
    \item[3.] $H \trianglelefteq G$,
    \item[4.] $H \cap K = 1$,
    \item[5.] for all $h \in H$ and $k \in K$, $khk^{-1} = k \cdot h = \varphi(k)(h).$
\end{enumerate} $ $ \\
\textbf{Definition - Semidirect Product}: Let $H$ and $K$ be groups and let $\varphi$ be a homomorphism from $K$ into $\aut(H)$. The group described in Theorem 10 is called the \textit{semidirect product} of $H$ and $K$ with respect to $\varphi$ and will be denoted by $H \rtimes_\varphi K$ (when there is no danger of confusion we shall simply write $H \rtimes K$). \\ \\
\textbf{Proposition 5.11}: Let $H$ and $K$ be groups and let $\varphi: K \rightarrow \aut(H)$ be a homomorphism. Then the following are equivalent: \begin{enumerate}
    \item the identity (set) map between $H \rtimes K$ and $H \times K$ is a group homomorphism (hence an isomorphism).
    \item $\varphi$ is the trivial homomorphism from $K$ into $\aut(H)$.
    \item $K \trianglelefteq H \rtimes K$. 
\end{enumerate} $ $ \\
\textbf{Theorem 5.12}: Suppose $G$ is a group with subgroups $H$ and $K$ such that \begin{enumerate}
    \item $H \trianglelefteq G$, and
    \item $H \cap K = 1$. 
\end{enumerate} Let $\varphi: K \rightarrow \aut(H)$ be the homomorphism defined by mapping $k \in K$ to the automorphism of left conjugation by $k$ on $H$. Then $HK \cong H \rtimes K$. In particular, if $G = HK$ with $H$ and $K$ satisfying (1) and (2), then $G$ is the semidirect product of $H$ and $K$. \\ \\
\textbf{Definition - Complement}: Let $H$ be a subgroup of the group $G$. A subgroup $K$ of $G$ is called a \textit{complement} for $H$ in $G$ if $G = H K$ and $H \cap K = 1$.
\subsection*{7. Introduction to Rings}
\textbf{Definition - Ring}: \begin{enumerate}
    \item A ring $R$ is a set together with two binary operations $+$ and $\times$ (called addition and multiplication) satisfying the following axioms: \begin{enumerate}[(i).]
        \item $(R, +)$ is an abelian group,
        \item $\times$ is associative: $(a \times b) \times c = a \times (b \times c)$ for all $a, b, c \in R$
        \item the distributive laws hold in $R$: for all $a, b, c \in R$ $$(a + b) \times c = (a \times c) + (b \times c) \text{ and } a \times (b + c) = (a \times b) + (a \times c)$$
    \end{enumerate}
    \item The ring $R$ is \textit{commutative} if multiplication is commutative.
    \item The ring $R$ is said to have an \textit{identity} (or contain a $1$) if there is an element $1 \in R$ with $1 \times a = a \times 1 = a$ for all $a \in R$.
\end{enumerate} $ $ \\
The additive identity in a ring will always be denoted by 0. \\ \\
\textbf{Definition - Field, Division Ring/Skew Field}: A ring $R$ with identity 1, where $1 \neq 0$, is called a \textit{division ring} (or \textit{skew
field}) if every nonzero element $a \in R$ has a multiplicative inverse, i.e., there exists $b \in R$ such that $ab = ba = 1$. A commutative division ring is called a \textit{field}. \\ \\
\textit{Trivial rings} are obtained by taking $R$ to be any abelian group under addition and defining the multiplication of any two elements in $R$ to be 0. If $R = \{0\}$ is the trivial group, then the resulting ring $R$ is called the \textit{zero ring}, denoted $R = 0.$ Note that the zero ring is the only ring where $1 = 0$, so we immediately exclude this ring by imposing the standard condition that $1 \neq 0.$ \\ \\
\textbf{Definition - The (real) Hamilton Quaternions}: Let $\mathbb{H}$ be the collection of elements of the form
$a + bi + cj + dk$ where $a, b, c, d \in \R$ are real numbers (loosely, ``polynomials in $1, i, j, k$ with real coefficients'') where addition is defined ``componentwis'' by $$(a+bi+cj+dk) + (a' + b'i + c'j + d'k) = (a + a') + (b + b')i + (c + c')j + (d + d')k$$ and multiplication is defined using the distributive law and simplifying using the relations $$i^2 = j^2 = k^2 = -1, ij = -ji = k, jk = -kj = i, ki = -ik = j$$ where the real coefficients commute with $i, j, k.$ \\ The real Hamiltonian Quaternions (similarly is true for rational coefficients) form a non-commutative division ring with identity $1 = 1 + 0(i + j + k)$. Inverses are given by $(a + bi + cj + dk)^{-1} = \mathlarger{\frac{a - bi - cj - dk}{a^2 + b^2 + c^2 + d^2}}.$ \\ \\
\textbf{Proposition 7.1}: Let $R$ be a ring. Then \begin{enumerate}
    \item $0a = a0 = 0$ for all $a \in R$.
    \item $(-a)b = a(-b) = -(ab)$ for all $a, b \in R$ (recall $-a$ is the additive inverse of $a$).
    \item $(-a)(-b) = ab$ for all $a, b \in R$.
    \item if $R$ has an identity $1$, then the identity is unique and $-a = (-1)a$.
\end{enumerate} $ $ \\
\textbf{Definition - Zero Divisor, Unit}: Let $R$ be a ring. \begin{enumerate}
    \item A nonzero element $a \in R$ is called a \textit{zero divisor} if there is a nonzero element $b \in R$ such that either $ab = 0$ or $ba = 0$.
    \item Assume $R$ has an identity $1 \neq 0$. An element $u$ of $R$ is called a \textit{unit} in $R$ if there is some $v$ in $R$ such that $uv = vu = 1$. The set of units in $R$ is denoted $R^\times$. 
\end{enumerate} $ $ \\
\textbf{Consequences of the Above Definitions}: \begin{enumerate}
    \item Note that $R^\times$ forms a group under multiplication and will be referred to as the \textit{group of units of $R$}.
    \item In this terminology a field is just a commutative ring $F$ with identity $1 \neq 0$ in which every nonzero element is a unit, i.e., $F^\times = F - \{0\}$.
    \item Note that a zero divisor can never be a unit.
    \item (2) and (3) imply that a field has no zero divisors.
    \item $\Z/n\Z$ is a field iff $n$ is prime.
    \item $\Q(\sqrt{D})$ is called a \textit{quadratic field} for $D$ is a square-free integer.
\end{enumerate} $ $ \\
\textbf{Definition - Integral Domain}: A commutative ring with identity $1 \neq 0$ is called an \textit{integral domain} if it has no zero divisors. \\ \\
\textbf{Proposition 7.2}: Assume $a, b, c$ are elements of any ring with $a$ not a zero divisor. If $ab = ac$, then either $a = 0$ or $b = c$ (i.e., if $a \neq 0$ we can cancel the $a$'s). In particular, if $a, b, c$ are any elements in an integral domain and $ab = ac$, then either $a = 0$ or $b = c$. \\ \\
\textbf{Corollary 7.3 - Wedderburn's little theorem}: Any finite integral domain is a field. \\ \\
\textbf{Definition - Subring}: A \textit{subring} of the ring $R$ is a subgroup of $R$ that is closed under multiplication. \\ \\
The conditions for checking if a subset $S \subseteq R$ is a subring are that it is nonempty and closed under subtraction (addition and inverses under addition) and under multiplication. \\ \\
The \textit{Gaussian Integers} are all numbers of the form $a + bi,$ for integers $a, b.$ \\ \\
\textbf{Definition - Ring of Integers in the Quadratic Field $\Q(\sqrt{D})$}: Define $$\mathcal{O} = \mathcal{O}_{\Q(\sqrt{D})} = \Z[\omega] = \{a + b \omega | a, b \in \Z\},$$ where $\omega = \begin{cases}
    \sqrt{D}, &\text{ if } D \equiv 2, 3 \pmod{4} \\
    \mathlarger{\frac{1 + \sqrt{D}}{2}}, &\text{ if } D \equiv 1 \pmod{4}. \\
\end{cases}$ \\ \\ \\
\textbf{Definition - Field Norm}: Define the \textit{field norm} $N: \Q(\sqrt{D}) \rightarrow \Q$ by $$N(a + b\sqrt{D}) = (a + b\sqrt{D})(a - b\sqrt{D}) = a^2 - Db^2 \in \Q.$$ If the quadratic field $\Q(\sqrt{D})$ is in some $w = \frac{1 + \sqrt{D}}{2}$, then the norm is defined to be the conjugate of  \\ \\
\textbf{Definition - Polynomial, Degree, Monic, $R[x]$}: Given a ring $R$, the formal sum $$a_nx^n + a_{n - 1}x^{n - 1} + \dots + a_1x + a_0$$ with $n \geq 0$ and each $a_i \in R$ is called a \textit{polynomial} in $x$ with coefficients $a_i \in R$. If the \textit{leading coefficient} $a_n \neq 0$, then this polynomial is said to be of \textit{degree} $n$. $a_nx^n$ is called the \textit{leading term}. This polynomial is said to be monic if $a_n = 1$. The set of all such polynomials is called the \textit{ring of polynomials in the variable $x$ with coefficients in $R$} and will be denoted $R[x]$. \\ \\
The ring $R$ appears in $R[x]$ as the \textit{constant polynomials}, i.e. $R \subset R[x]$. Note that by definition of the multiplication, $R[x]$ is a commutative ring with identity (the identity 1 from $R$). \\ \\
\textbf{Proposition 7.4}: Let $R$ be an integral domain and let $p(x), q(x)$ be nonzero elements of $R[x]$. Then \begin{enumerate}
    \item $\deg(p(x)q(x)) = \deg p(x) + \deg q(x)$,
    \item the units of $R[x]$ are just the units of $R$,
    \item $R[x]$ is an integral domain.
\end{enumerate} $ $ \\
Given a ring $R$ we define $M_n(R)$ to be the set of all $n \times n$ matrices with entries from $R$. The element $(a_{ij})$ of $M_n(R)$ is an $n \times n$ square array
of elements of $R$ whose entry in row $i$ and column $j$ is $a_{ij} \in R$. $M_n(R)$ forms a ring. The units in $M_n(R)$ are $GL_n(R)$, the group of invertible $n \times n$ matrices with entries in $R$. \\ \\
An element $(a_{ij})$ of $M_n(R)$ is called a \textit{scalar matrix} if for some $a \in R, a_{ii} = a$ for all $i \in \{ 1, \dots, n\}$ and $a_{ij} = 0$ for all $i \neq j$ (i.e., all diagonal entries equal $a$ and all off-diagonal entries are $0$). \\ \\
If $S$ is a subring of $R$ then $M_n(S)$ is a subring of $M_n(R)$. \\ \\
\textbf{Definition - Group Ring}: For a finite group $G = \{g_1, g_2, \dots, g_n\}$, define the \textbf{group ring}, $RG$, of $G$ with coefficients in $R$ to be the set of all formal sums $$a_1g_1 + a_2g_2 + \dots + a_ng_n, \text{ for } a_i \in R, 1 \leq i \leq n.$$ Addition is defined component-wise and multiplication is defined using the distributive law and the group relations. \\ \\
$\Z G$ (called the \textit{integral group ring of} $G$) is a subring of $\Q G$ (the \textit{rational group ring of} $G$). Furthermore, if $H$ is a subgroup of $G$ then $\R H$ is a subring of $\R G$. \\ \\
\textbf{Definition - Ring Homomorphism, Kernel}. Let $R$ and $S$ be rings. \begin{enumerate}
    \item A \textit{ring homomorphism} is a map $\varphi: R \rightarrow S$ satisfying
    \begin{enumerate}[(i).]
        \item $\varphi(a + b) = \varphi(a) + \varphi(b)$ for all $a, b \in R$ (so $\varphi$ is a group homomorphism on the additive groups) and
        \item $\varphi(ab) = \varphi(a) \varphi(b)$ for all $a, b \in R$.
    \end{enumerate}
    \item The \textit{kernel} of the ring homomorphism $\varphi$, denoted $\ker \varphi$, is the set of elements of $R$ that map to 0 in $S$ (i.e., the kernel of $\varphi$ viewed as a homomorphism of additive groups).
    \item A bijective ring homomorphism is called an \textit{isomorphism}. 
\end{enumerate} $ $ \\
We use $\cong$ to denote an isomorphism of rings, similarly to groups. \\ \\
\textbf{Proposition 7.5}: Let $R$ and $S$ be rings and let $\varphi: R \rightarrow S$ be a homomorphism. \begin{enumerate}
    \item The image of $\varphi$ is a subring of $S$.
    \item The kernel of $\varphi$ is a subring of $R$. Furthermore, if $\alpha \in \ker \varphi$ then $r \alpha$ and $\alpha r \in \ker \varphi$ for every $r \in R$, i.e., $\ker \varphi$ is closed under multiplication by elements from $R$.
\end{enumerate} $ $ \\
\textbf{Definition - Quotient Ring}: This ring of cosets is called the \textit{quotient ring} of $R$ by $I = \ker \varphi$ and is denoted $R / I$. \\ \\
\textbf{Definition - (Left/Right) Ideal}: Let $R$ be a ring, let $I$ be a subset of $R$ and let $r \in R$. \begin{enumerate}
    \item $rI = \{ra | a \in I\}$ and $Ir = \{ar | a \in I\}$. 
    \item A subset $I$ of $R$ is a \textit{left ideal} of $R$ if \begin{enumerate}[(i).]
        \item $I$ is a subring of $R$, and
        \item $I$ is closed under left multiplication by elements from $R$, i.e., $rI \subseteq I$ for all $r \in R$. \\ \\
        \hspace*{-1.2cm} Similarly $I$ is a \textit{right ideal} if (i) holds and in place of (ii) one has
        \item[(ii)'.] $I$ is closed under right multiplication by elements from $R$, i.e., $Ir \subseteq I$ for all $r \in R$. 
    \end{enumerate}
    \item A subset $I$ that is both a left ideal and a right ideal is called an \textit{ideal} (or, for added emphasis, a \textit{two-sided ideal}) of $R$. 
\end{enumerate} $ $ \\
\textbf{Proposition 7.6}: Let $R$ be a ring and let $I$ be an ideal of $R$. Then the (additive) quotient group $R/I$ is a ring under the binary operations: $$(r + I) + (s + I) = (r + s) + I \text{ and } (r + I) x (s + I) = (rs) + I$$ for all $r, s \in R$. Conversely, if $I$ is any subgroup such that the above operations are well defined, then $I$ is an ideal of $R$. \\ \\
\textbf{Definition - Quotient Ring}: When $I$ is an ideal of $R$ the ring $R/I$ with the operations in the previous proposition is called the \textit{quotient ring} of $R$ by $I$. \\ \\
\textbf{Theorem 7.7}: \begin{enumerate}
    \item (\textit{The First Isomorphism Theorem for Rings}) If $\varphi: R \rightarrow S$ is a homomorphism of rings, then the kernel of $\varphi$ is an ideal of $R$, the image of $\varphi$ is a subring of $S$ and $R/\ker \varphi$ is isomorphic as a ring to $\varphi(R)$.
    \item If $I$ is any ideal of $R$, then the map $$R \rightarrow R/I \hspace{1cm} \text{ defined by } \hspace{1cm} r \mapsto r + I $$ is the surjective ring homomorphism with kernel $I$ (this homomorphism is called the natural projection of $R$ onto $R/I$). Thus every ideal is the kernel of a ring homomorphism and vice versa. 
\end{enumerate} $ $ \\
Similarly to groups, we may write $\overline{r} = r + I$ for some ideal $I$ and $\overline{r} + \overline{s} = \overline{r + s}$ and $\overline{r} \text{ } \overline{s} = \overline{rs}$. \\ \\
\textbf{Theorem 7.8}: Let $R$ be a ring. \begin{enumerate}
    \item (\textit{The Second Isomorphism Theorem for Rings}) Let $A$ be a subring and let $B$ be an ideal of $R$. Then $A + B = \{a + b | a \in A, b \in B\}$ is a subring of $R$, $A \cap B$ is an ideal of $A$ and $(A + B)/ B \cong A / (A \cap B)$. 
    \item (\textit{The Third Isomorphism Theorem for Rings}) Let $I$ and $J$ be ideals of $R$ with $I \subseteq J$. Then $J/I$ is an ideal of $R/I$ and $(R/I) / (J/I) \cong R / J$.
    \item (\textit{The Fourth or Lattice Isomorphism Theorem for Rings}) Let $I$ be an ideal of $R$. The correspondence $A \leftrightarrow A/I$ is an inclusion preserving bijection between the set of subrings $A$ of $R$ that contain $I$ and the set of subrings of $R / I$. Furthermore, $A$ (a subring containing $I$) is an ideal of $R$ if and only if $A/I$ is an ideal of $R / I$.
\end{enumerate} $ $ \\
\textbf{Definition - Sum and Product of Ideals}: Let $I$ and $J$ be ideals of $R$. \begin{enumerate}
    \item Define the \textit{sum} of $I$ and $J$ by $I + J = \{a + b | a \in I, b \in J\}$.
    \item Define the \textit{product} of $I$ and $J$, denoted by $IJ$, to be the set of all finite sums of elements of the form $ab$ with $a \in I$ and $b \in J.$ 
    \item For any $n \geq 1$, define the $n$th power of $I$, denoted by $I^n$, to be the set consisting of all finite sums of elements of the form $a_1 a_2 \dots a_n$ with $a_i \in I$ for all $i$. Equivalently, $I^n$ is defined inductively by defining $I^1 = I$, and $I^n = I I^{n - 1}$ for $n = 2, 3, \dots.$
\end{enumerate} $ $ \\
\textbf{Definition - $(A)$, Principle Ideal, Finitely Generated Ideal}: Let $A$ be any subset of the ring $R$ with identity $1 \neq 0$. \begin{enumerate}
    \item Let $(A)$ denote the smallest ideal of $R$ containing $A$, called the \textit{ideal generated by} $A$.
    \item Let $RA$ denote the set of all finite sums of elements of the form $ra$ with $r \in R$ and $a \in A$ i.e., $RA = \{r_1a_1 + r_2a_2 + \dots + r_n a_n | r_i \in R, a_i \in A, n \in \Z^+\}$ (where the convention is $RA = 0$ if $A = \emptyset$). \\
    Similarly, $AR = \{a_1 r_1 + a_2 r_2 + \dots + a_n r_n | r_i \in R, a_i \in A, n \in \Z^+\}$ and $RAR = \{r_1 a_1 r_1 + r_2 a_2 r_2 + \dots + r_n a_n r_n | r_i \in R, a_i \in A, n \in \Z^+\}$. 
    \item An ideal generated by a single element is called a \textit{principal ideal}.
    \item An ideal generated by a finite set is called a \textit{finitely generated ideal}.
\end{enumerate} $ $ \\
The (two-sided) ideal $I = (A)$ generated by some subset $A \subseteq R$ must be closed under multiplication of elements of $R$, so $I$ contains all elements of the form $ar, \forall a \in A, r \in R$. Thus, for any ring $R$, the ideal generated by $1$ is $R$, as $1r = r \in I, \forall r \in R$. \\ \\
When $A = \{a\}, \{a_1, a_2, \dots, a_n\}$, or $\{a_1, a_2, \dots\}$, we can write $(a), (a_1, a_2, \dots, a_n), (a_1, a_2, \dots)$ to mean $(A)$, respectively. \\ \\
$$(A) = \bigcap_{\substack{I \text{ an ideal} \\ A \subseteq I}} I,$$ in other words, the ideal $(A)$ generated by some set $A$ is the intersection of all ideals of $R$ containing the set $A$. \\ \\
Similarly, the \textit{left ideal generated by} $A$ is the intersection of all left ideals of $R$ that contain $A$. \\ \\
Then $RA$ is the left ideal generated by $A$, $AR$ is the right ideal generated by $A$ and $RAR$ is the (two-sided) ideal generated by $A$. If $R$ is commutative then $RA = AR = RAR = (A)$. \\ \\
\textbf{Proposition 7.9}: Let $I$ be an ideal of $R$ with identity $1 \neq 0$. \begin{enumerate}
    \item $I = R$ if and only if $I$ contains a unit.
    \item Assume $R$ is commutative. Then $R$ is a field if and only if its only ideals are $0$ and $R$.
\end{enumerate} $ $ \\
\textbf{Corollary 7.10}: If $R$ is a field then any nonzero ring homomorphism from $R$ into another ring is an injection. \\ \\
\textbf{Definition - Maximal Ideal}: An ideal $M$ in an arbitrary ring $S$ is called a \textit{maximal ideal} if $M \neq S$ and the only ideals containing $M$ are $M$ and $S$. \\ \\
\textbf{Proposition 7.11}: In a ring with identity every proper ideal is contained in a maximal ideal. \\ \\
\textbf{Proposition 7.12}: Assume $R$ is a commutative ring with identity $1 \neq 0$. The ideal $M$ is a maximal ideal if and only if the quotient ring $R/M$ is a field. \\ \\
\textbf{Definition - Prime Ideal}: Assume $R$ is a commutative ring with identity $1 \neq 0$. An ideal $P$ is called a \textit{prime ideal} if $P \neq R$ and whenever the product $ab$ of two elements $a, b \in R$ is an element of $P$, then at least one of $a$ and $b$ is an element of $P$. \\ \\
\textbf{Proposition 7.13}: Assume $R$ is a commutative ring with identity $1 \neq 0$.. Then the ideal $P$ is a prime ideal in $R$ if and only if the quotient ring $R/P$ is an integral domain. \\ \\
\textbf{Corollary 7.14}: Assume $R$ is commutative. Every maximal ideal of $R$ is a prime ideal. \\ \\
\textbf{Theorem 7.15}: Let $R$ be a commutative ring. Let $D$ be any nonempty subset of $R$ that does not contain $0$, does not contain any zero divisors and is closed under multiplication (i.e., $ab \in D$ for all $a, b \in D$). Then there is a commutative ring $Q$ with $1$ such that $Q$ contains $R$ as a subring and every element of $D$ is a unit in $Q$. The ring $Q$ has the following additional properties. \begin{enumerate}
    \item every element of $Q$ is of the form $rd^{-1} = d^{-1}r$ for some $r \in R$ and $d \in D$. In particular, if $D = R - \{0\}$ then $Q$ is a field.
    \item (uniqueness of $Q$) The ring $Q$ is the ``smallest'' ring containing $R$ in which all elements of $D$ become units, in the following sense. Let $S$ be any commutative ring with identity and let $\varphi: R \rightarrow S$ be any injective ring homomorphism such that $\varphi(d)$ is a unit in $S$ for every $d \in D$. Then there is an injective homomorphism $\phi: Q \rightarrow S$ such that $\phi|_R = \varphi.$ In other words, any ring containing an isomorphic copy of $R$ in which all the elements of $D$ become units must also contain an isomorphic copy of $Q$. 
\end{enumerate} $ $ \\
\textbf{Definition - Ring (Field) of Fractions, Quotient Field}: Let $R, D$ and $Q$ be as in Theorem 15. \begin{enumerate}
    \item The ring $Q$ is called the \textit{ring of fractions of D with respect to R} and is denoted $D^{-1}R$.
    \item If $R$ is an integral domain and $D = R - \{0\}$, $Q$ is called the \textit{field of fractions} or \textit{quotient field} of $R$.
\end{enumerate} $ $ \\
\textbf{Corollary 7.16}: Let $R$ be an integral domain (which means $R$ is commutative) and let $Q$ be the field of fractions of $R$. If
a field $F$ contains a subring $R'$ isomorphic to $R$ then the subfield of $F$ generated by $R'$ is isomorphic to $Q$. \\ \\
\textbf{Definition - Ring Direct Product}: We define a direct product of rings $R_1 \times R_2 \times \dots \times R_n$ (or for infinitely many $R_i$) as the set of ordered pairs $(r_1, r_2, \dots, r_n), r_i \in R_i$, where addition and multiplication are defined component-wise, i.e., $$(r_1, r_2) + (s_1, s_2) = (r_1 + s_1, r_2 + s_2) \text{ and } (r_1, r_2)(s_1, s_2) = (r_1 s_1, r_2 s_2).$$ \\
Then a map from a ring $R$ into a direct product of rings is a homomorphism iff the induced maps into each component of the direct product are homomorphisms. \\ \\
\textbf{Definition - Comaximal}. The ideals $A$ and $B$ of the commutative ring $R$ with identity $1 \neq 0$ are said to be \textit{comaximal} if $A + B = R$. \\ \\
\textbf{Theorem 7.17 - Chinese Remainder Theorem}: Let $A_1, A_2, \dots, A_k$ be ideals in commutative ring $R$ with identity $1 \neq 0$. The map $$R \rightarrow R/A_1 \times R/A_2 \times \dots \times R/A_k \text{ defined by } r \mapsto (r + A_1, r + A_2, \dots, r + A_k)$$ is a ring homomorphism with kernel $A_1 \cap A_2 \cap \dots \cap A_k.$ If for each $i, j \in \{ 1, 2, \dots, k\}$ with $i \neq j$ the ideals $A_i$ and $A_j$ are comaximal, then this map is surjective and $A_1 \cap A_2 \cap \dots \cap A_k = A_1 A_2 \dots A_k$, so $$R / (A_1 A_2 \dots A_k) = R / (A_1 \cap A_2 \cap \dots \cap A_k) \cong R/A_1 \times R/A_2 \times \dots \times R/A_k.$$ \\
\textbf{Corollary 7.18}: Let $n$ be a positive integer and let $P_1^{\alpha_1} P_2^{\alpha_2} \dots P_k^{\alpha_k}$ be its factorization into powers of distinct primes. Then $$\Z/n\Z \cong (\Z/P_1^{\alpha_1}\Z) \times (\Z/P_2^{\alpha_2}\Z) \times \dots \times (\Z/P_k^{\alpha_k}\Z),$$ as rings, so in particular we have the following isomorphism of multiplicative groups: $$(\Z/n\Z)^\times \cong (\Z/P_1^{\alpha_1}\Z)^\times \times (\Z/P_2^{\alpha_2}\Z)^\times \times \dots \times (\Z/P_k^{\alpha_k}\Z)^\times.$$
\subsection*{8. Euclidean Domains, Principal Ideal Domains, and Unique Factorization Domains}
\textbf{Definition - (Positive) Norm}: Any function $N: R \rightarrow \Z^+ \cup \{0\}$ with $N(0) = 0$ is called a \textit{norm} on the integral domain $R$. If $N(a) > 0$ for a $a \neq 0$ define $N$ to be a \textit{positive norm}. \\ \\
\textbf{Definition - Euclidean Domain/Division Algorithm, Quotient, Remainder}: The integral domain $R$ is said to be a \textit{Euclidean Domain} (or possess a \textit{Division Algorithm}) if there is a norm $N$ on $R$ such that for any two elements $a$ and $b$ of $R$ with $b \neq 0$ there exist elements $q$ and $r$ in $R$ with $$a = bq + r, \text{ with } r = 0 \text{ or } N(r) < N(b).$$ The element $q$ is called the \textit{quotient} and the element $r$ the \textit{remainder} of the division. \\ \\
\textbf{Definition - Euclidean Algorithm}: We care about the existence of a division algorithm on an integral domain $R$ because it allows for a \textit{Euclidean algorithm} for two elements $a, b \in R$, \begin{align}
    a &= q_0b + r_0 \\
    b &= q_1 r_0 + r_1 \\ 
    r_0 &= q_2 r_1 + r_2 \\
    &\vdots \\
    r_{n - 2} &= q_n r_{n - 1} + r_n \\
    r_{n - 1} &= q_{n + 1} r_n
\end{align} The sequence of $(r_i)$ necessarily terminates at some $i = n$ as $N(b) > N(r_0) > \dots > N(r_n)$ is a decreasing sequence of integers bounded below at 0. \\ \\
\textbf{Proposition 8.1}: Every ideal in a Euclidean Domain is principal. More precisely, if $I$ is any nonzero ideal in the Euclidean Domain $R$ then $I = (d)$, where $d$ is any nonzero
element of $I$ of minimum norm. \\ \\
\textbf{Definition - Greatest Common Divisor}: Let $R$ be a commutative ring and let $a, b \in R$ with $b \neq 0$. \begin{enumerate}
    \item $a$ is said to be a \textit{multiple} of $b$ if there exists an element $x \in R$ with $a = bx$. In this case $b$ is said to \textit{divide} $a$ or be a \textit{divisor} of $a$, written $b | a$.
    \item A \textit{greatest common divisor} of $a$ and $b$ is a nonzero element $d$ such that \begin{enumerate}[(i).]
        \item $d | a$ and $d | b$, and
        \item if $d' | a$ and $d' | b$ then $d' | d$.
    \end{enumerate}
    A greatest common divisor of $a$ and $b$ will be denoted by $GCD(a, b)$, or (abusing the notation) simply $(a, b)$. 
\end{enumerate} $ $ \\
$b|a$ iff $a \in (b)$ iff $(a) \subseteq (b)$. \\ \\
If $I$ is the ideal of $R$ generated by $a$ and $b$, then $d$ is a greatest common divisor of $a$ and $b$ if \begin{enumerate}[(i).]
    \item $I$ is contained in the principal ideal $(d)$, and
    \item if $(d')$ is any principal ideal containing $I$ then $(d) \subseteq (d')$. 
\end{enumerate} This is essentially saying that $(d)$ is the unique smallest ideal containing $I = (a, b).$ \\ \\
\textbf{Proposition 8.2}: If $a$ and $b$ are nonzero elements in the commutative ring $R$ such that the ideal generated by $a$ and $b$ is a principal ideal $(d)$, then $d$ is a greatest common divisor of $a$ and $b$. \\ \\
\textbf{Definition - Bezout Domain}: An integral domain in which every ideal $(a, b)$ generated by two elements is principal is called a \textit{Bezout Domain}. \\ \\
\textbf{Proposition 8.3}: Let $R$ be an integral domain. If two elements $d$ and $d'$ of $R$ generate the same principal ideal, i.e., $(d) = (d')$, then $d' = ud$ for some unit $u$ in $R$. In particular, if $d$ and $d'$ are both greatest common divisors of $a$ and $b$, then $d' = ud$ for some unit $u$. \\ \\
\textbf{Theorem 8.4}: Let $R$ be a Euclidean Domain and let a and $b$ be nonzero elements of $R$. Let $d = r_n$ be the last nonzero remainder in the Euclidean Algorithm for $a$ and $b$ described at the beginning of this chapter. Then \begin{enumerate}
    \item $d$ is a greatest common divisor of $a$ and $b$, and
    \item the principal ideal $(d)$ is the ideal generated by $a$ and $b$. In particular, $d$ can be written as an $R$-linear combination of $a$ and $b$, i.e., there are elements $x$ and $y$ in $R$ such that $$d = ax + by.$$
\end{enumerate} $ $ \\
\textbf{Definition - Universal Side Divisor}: Let $\tilde{R} = R^\times \cup \{0\}$ denote the collection of units of commutative ring $R$ together with $0$. An element $u \in R - \tilde{R}$ is called a \textit{universal side divisor} if for every $x \in R$ there is some $z \in \tilde{R}$ such that $u$ divides $x - z$ in $R$, i.e. $x = qu + z$, where $z$ is either a unit or $0$. \\ \\
\textbf{Proposition 8.5}: Let $R$ be an integral domain that is not a field. If $R$ is a Euclidean Domain then there are universal side divisors in $R$. \\ \\
\textbf{Definition - Principal Ideal Domain (P.I.D.)}: A \textit{Principal Ideal Domain (P.I.D.)} is an integral domain in which every ideal is principal. \\ \\
Proposition 8.1 showed that every Euclidean domain is a principle ideal domain, so a Euclidean domain is a stronger condition than a P.I.D. \\ \\
\textbf{Proposition 8.6}: Let $R$ be a Principal Ideal Domain and let $a$ and $b$ be nonzero elements
of $R$. Let $d$ be a generator for the principal ideal generated by $a$ and $b$. Then \begin{enumerate}
    \item $d$ is a greatest common divisor of $a$ and $b$,
    \item $d$ can be written as an $R$-linear combination of $a$ and $b$, i.e., there are elements $x$ and $y$ in $R$ with $$d = ax + by.$$
    \item $d$ is unique up to multiplication by a unit of $R$. 
\end{enumerate} $ $ \\
\textbf{Proposition 8.7}: Every nonzero prime ideal in a Principal Ideal Domain is a maximal ideal. \\ \\
\textbf{Corollary 8.8}: If $R$ is any commutative ring such that the polynomial ring $R[x]$ is a Principal Ideal Domain (or a Euclidean Domain), then $R$ is necessarily a field. \\ \\
\textbf{Definition - Dedekind-Hasse Norm}: Define $N$ to be a \textit{Dedekind-Hasse norm} if $N$ is a positive norm and for every nonzero $a, b \in R$ either $a$ is an element of the ideal $(b)$ or there is a nonzero element in the ideal $(a, b)$ of norm strictly smaller than the norm of $b$ (i.e., either $b$ divides $a$ in $R$ or there exist $s, t \in R$ with $0 < N(sa - tb) < N(b)$). \\ \\
Note that when $s = 1$ in the above definition, this is equivalent to $R$ being a Euclidean domain. \\ \\
\textbf{Proposition 8.9}: The integral domain $R$ is a P.I.D. if and only if $R$ has a Dedekind-Hasse norm. \\ \\
\textbf{Definition - Irreducible, Prime, Associate}: Let $R$ be an integral domain. \begin{enumerate}
    \item Suppose $r \in R$ is nonzero and is not a unit. Then $r$ is called \textit{irreducible} in $R$ if whenever $r = ab$ with $a, b \in R$, at least one of $a$ or $b$ must be a unit in $R$. Otherwise $r$ is said to be \textit{reducible}.
    \item The nonzero element $p \in R$ is called \textit{prime} in $R$ if the ideal $(p)$ generated by $p$ is a prime ideal. In other words, a nonzero element $p$ is a prime if it is not a unit and whenever $p | ab$ for any $a, b \in R$, then either $p | a$ or $p | b$.
    \item Two elements $a$ and $b$ of $R$ differing by a unit are said to be associate in $R$ (i.e., $a = ub$ for some unit $u$ in $R$).
\end{enumerate} $ $ \\
If $R$ is a Principal Ideal Domain however, the notions of prime and irreducible elements are the same. \\ \\
\textbf{Proposition 8.10}: In an integral domain a prime element is always irreducible. \\ \\
\textbf{Proposition 8.11}: In a Principal Ideal Domain a nonzero element is a prime if and only if it is irreducible. \\ \\
\textbf{Definition - Unique Factorization Domain (U.F.D.)}: A \textit{Unique Factorization Domain (U.F.D.)} is an integral domain $R$ in which every nonzero element $r \in R$ which is not a unit has the following two properties: \begin{enumerate}
    \item $r$ can be written as a finite product of irreducible $p_i$ of $R$ (not necessarily distinct): $r = p_1 p_2 \dots p_n$ and
    \item the decomposition in (1) is unique up to associates: namely, if $r = q_1 q_2 \dots q_m$ is another factorization of $r$ into irreducibles, then $m = n$ and there is some renumbering of the factors so that $p_i$ is associate to $q_i$ for $i = 1, 2, \dots, n$. 
\end{enumerate} $ $ \\
\textbf{Proposition 8.12}: In a Unique Factorization Domain a nonzero element is a prime if and only if it is irreducible. \\ \\
\textbf{Proposition 8.13}: Let $a$ and $b$ be two nonzero elements of the Unique Factorization Domain $R$ and suppose $$a = up_1^{e_1} \dots p_n^{e_n} \text{ and } b = vp_1^{f_1} \dots p_n^{f_n}$$ are prime factorizations for $a$ and $b$, where $u$ and $v$ are units, the primes $p_1, p_2, \dots, p_n$ are distinct and the exponents $e_i$ and $f_i$ are $\geq 0$. Then the element $$d = p_1^{\min(e_1, f_1)} p_2^{\min(e_2, f_2)} \dots p_n^{\min(e_n, f_n)}$$ (where $d = 1$ if all the exponents are $0$) is a greatest common divisor of $a$ and $b$. \\ \\
\textbf{Theorem 8.14}: Every Principal Ideal Domain is a Unique Factorization Domain. In particular, every Euclidean Domain is a Unique Factorization Domain. \\ \\
\textbf{Corollary 8.15 - Fundamental Theorem of Arithmetic}: The integers $\Z$ are a Unique Factorization Domain. \\ \\
\textbf{Corollary 8.16}: Let $R$ be a P.I.D. Then there exists a multiplicative Dedekind-Hasse norm on $R$. \\ \\
\textbf{Lemma 8.17}: The prime number $p \in Z$ divides an integer of the form $n^2 + 1$ if and only if $p$ is either $2$ or is an odd prime congruent to $1$ modulo $4$. \\ \\
\textbf{Proposition 8.18}: \begin{enumerate}
    \item (\textit{Fermat's Theorem on Sums of Squares}) The prime $p$ is the sum of two integer squares, $p = a^2 + b^2, a, b \in \Z$, if and only if $p = 2$ or $p \equiv 1 \pmod{4}$. Except for interchanging $a$ and $b$ or changing the signs of $a$ and $b$, the representation of $p$ as a sum of two squares is unique.
    \item  The irreducible elements in the Gaussian integers $Z[i]$ are as follows: \begin{enumerate}
        \item $1 + i$ (which has norm $2$),
        \item the primes $p \in \Z$ with $p \equiv 3 \pmod{4}$ (which have norm $p^2$), and
        \item $a + bi, a - bi$, the distinct irreducible factors of $p = a^2 + b^2 =  (a + bi)(a - bi)$ for the primes $p \in Z$ with $p \equiv 1 \pmod{4}$ (both of which have norm $p$).
    \end{enumerate}
\end{enumerate} $ $ \\
\textbf{Corollary 8.19}: Let $n$ be a positive integer and write $$n = 2^k p_1^{a_1} \dots p_r^{a_r} q_1^{b_1} \dots q_s^{b_s}$$ where $p_1, \dots, p_r$ are distinct primes congruent to $1 \pmod{4}$ and $q_1, \dots, q_s$ are distinct primes congruent to $3 \pmod{4}$. Then $n$ can be written as a sum of two squares in $\Z$, i.e., $n = A^2 + B^2$ with $A, B \in Z,$ if and only if each $b_i$ is even. Further, if this condition on $n$ is satisfied. then the number of representations of $n$ as a sum of two squares is $4(a_1 + 1)(a_2 + 1) \dots (a_r + 1)$. \\ \\
In summary of all of chapter 8, $$\text{fields} \subset \text{Euclidean Domains} \subset \text{P.I.D.s} \subset \text{U.F.D.s} \subset \text{integral domains}.$$
\subsection*{9. Polynomial Rings}
In this chapter the ring $R$ will always denote a commutative ring with identity $1 \neq 0$. \\ \\
The polynomial ring $R[x]$ is all formal sums of the form $$a_nx^n + a_{n - 1}x^{n - 1} + \dots + a_1x + a_0, n \geq 0, a_i \in R.$$
\textbf{Proposition 9.1}: Let $R$ be an integral domain and let $p(x), q(x)$ be nonzero elements of $R[x]$. Then \begin{enumerate}
    \item $\deg(p(x)q(x)) = \deg p(x) + \deg q(x)$,
    \item the units of $R[x]$ are just the units of $R$,
    \item $R[x]$ is an integral domain.
\end{enumerate} $ $ \\
If $R$ is is an integral domain then the quotient field of $R[x]$ consists of all quotients $\frac{q(x)}{p(x)}$, where $q(x)$ is not the zero polynomial, and is called the field of rational functions in $x$ with coefficients in $R$. For an integral domain $R$, the quotient ring of $R[x]$ by a prime ideal $pR[x]$ is an integral domain. \\ \\
\textbf{Proposition 9.2}: Let $I$ be an ideal of the ring $R$ and let $(I) = I[x]$ denote the ideal of $R[x]$ generated by $I$ (the set of polynomials with coefficients in $I$). Then $$R[x]/(I) \cong R/I[x].$$ In particular, if $I$ is a prime ideal of $R$ then $(I)$ is a prime ideal of $R[x]$. \\ \\
\textbf{Definition - Multivariate Polynomial Rings}: The \textit{polynomial ring in the variables} $x_1, x_2, \dots, x_n$ with coefficients in $R$, denoted $R[x_1, x_2, \dots, x_n]$, is defined inductively by $$R[x_1, x_2, \dots, x_n] = R[x_1, x_2, \dots, x_{n - 1}][x_n].$$ Elements of this ring are of the form $$ax_1^{d_1} \dots x_n^{d_n}, d_i \geq 0$$ where $a \in R$ is the \textit{coefficient} of the term, the exponent $d_i$ is called the \textit{degree in} $x_i$ of the term and the sum $d = d_1 + d_2 + \dots + d_n$ is called the \textit{degree} of the term. The ordered $n$-tuple $(d_1, d_2, \dots, d_n)$ is the \textit{multidegree} of the term. A monic term $x_1^{d_1} \dots x_n^{d_n}$ is called simply a \textit{monomial} and is the \textit{monomial part} of the term $ax_1^{d_1} \dots x_n^{d_n}$. The \textit{degree} of a nonzero polynomial is the largest degree of any of its monomial terms. \\
A polynomial is called \textit{homogeneous} or a \textit{form} if all its terms have the same degree. If $f$ is a nonzero polynomial in $n$ variables, the sum of all the monomial terms in $f$ of degree $k$ is called the \textit{homogeneous component of $f$ of degree $k$}. \\
If $f$ has degree $d$ then $f$ may be written uniquely as the sum $f_0 + f_1 + \dots + f_d$, where $f_k$ is the homogeneous component of $f$ of degree $k$, for $0 \leq k \leq $d (where some $f_k$ may be zero). \\ \\
\textbf{Theorem 9.3}: Let $F$ be a field. The polynomial ring $F[x]$ is a Euclidean Domain. Specifically, if $a(x)$ and $b(x)$ are two polynomials in $F[x]$ with $b(x)$ nonzero, then there are \textit{unique} $q(x)$ and $r(x)$ in $F[x]$ such that $$a(x) = q(x)b(x) + r(x), \text{ with } r(x) = 0 \text{ or } \deg{r(x)} < \deg{\b(x)}.$$ \\
\textbf{Corollary 9.4}: If $F$ is a field, then $F[x]$ is a Principal Ideal Domain and a Unique Factorization Domain. \\ \\
\textbf{Proposition 9.5 - Gauss' Lemma}: Let $R$ be a Unique Factorization Domain with field of fractions $F$ and let $p(x) \in R[x]$. If $p(x)$ is reducible in $F[x]$ then $p(x)$ is reducible in $R[x]$. More precisely, if $p(x) = A(x)B(x)$ for some non-constant polynomials $A(x), B(x) \in F[x]$, then there are nonzero elements $r, s \in F$ such that $rA(x) = a(x)$ and $sB(x) = b(x)$ both lie in $R[x]$ and $p(x) = a(x)b(x)$ is a factorization in $R[x]$. \\ \\
Note that Gauss' Lemma is not saying that there exist $R$-multiples of $A(x)$ and $B(x)$, rather that there are $F$-multiples. \\ \\
\textbf{Corollary 9.6}: Let $R$ be a Unique Factorization Domain, let $F$ be its field of fractions and
let $p(x) \in R[x]$. Suppose the greatest common divisor of the coefficients of $p(x)$ is $1$. Then $p(x)$ is irreducible in $R[x]$ if and only if it is irreducible in $F[x]$. In particular, if $p(x)$ is a monic polynomial that is irreducible in $R[x]$, then $p(x)$ is irreducible in $F[x]$. \\ \\
\textbf{Theorem 9.7}: $R$ is a Unique Factorization Domain if and only if $R[x]$ is a Unique Factorization Domain. \\ \\
\textbf{Corollary 9.8}: If $R$ is a Unique Factorization Domain, then a polynomial ring in an arbitrary number of variables with coefficients in $R$ is also a Unique Factorization Domain. \\ \\
\textbf{Proposition 9.9}: Let $F$ be a field and let $p(x) \in F[x]$. Then $p(x)$ has a factor of degree one if and only if $p(x)$ has a root in $F$, i.e., there is an $\alpha \in F$ with $p(\alpha) = 0$. \\ \\
\textbf{Proposition 9.10}: A polynomial of degree two or three over a field $F$ is reducible if and only if it has a root in $F$. \\ \\
\textbf{Proposition 9.11}: Let $p(x) = a_nx^n + a_{n - 1}x^{n - 1} + \dots + a_0$ be a polynomial of degree $n$ with integer coefficients. If $r/s \in \Q$ is in lowest terms, (i.e., $r$ and $s$ are relatively prime integers) and $r/s$ is a root of $p(x)$, then $r$ divides the constant term and $s$ divides the leading coefficient of $p(x): r | a_0$ and $s | a_n$. In particular, if $p(x)$ is a monic polynomial with integer coefficients and $p(d) \neq  0$ for all integers $d$ dividing the constant term of $p(x)$, then $p(x)$ has no roots in $\Q$. \\ \\
\textbf{Proposition 9.12}: Let $I$ be a proper ideal in the integral domain $R$ and let $p(x)$ be a non-constant monic polynomial in $R[x]$. If the image of $p(x)$ in $(R/I)[x]$ cannot be factored in $(R/I)[x]$ into two polynomials of smaller degree, then $p(x)$ is irreducible in $R[x]$. \\ \\
\textbf{Proposition 9.13 - Eisenstein's Criterion}: Let $P$ be a prime ideal of the integral domain $R$ and let $f(x) = x^n +a_{n - 1}x^{n - 1} + \dots + a_1x + a_0$ be a polynomial in $R[x]$ (here $n \geq 1$). Suppose $a_{n - 1}, \dots, a_1, a_0$ are all elements of $P$ and suppose $a_0$ is not an element of $P^2$. Then $f(x)$ is irreducible in $R[x]$. \\ \\
\textbf{Corollary 9.14 - Eisenstein's Criterion for $\Z[x]$)}: Let $p$ be a prime in $\Z$ and let
$f(x) = x^n +a_{n - 1}x^{n - 1} + \dots + a_1x + a_0 \in \Z[x], n \geq 1$. Suppose $p$ divides $a_i$ for all $i \in \{0, 1, \dots, n - 1\}$ but that $p^2$ does not divide $a_0$. Then $j(x)$ is irreducible in both $\Z[x]$ and $\Q[x]$. \\ \\
\textbf{Proposition 9.15}: Let $F$ denote a field. The maximal ideals in $F[x]$ are the ideals $(f(x))$ generated by irreducible polynomials $f(x)$. In particular, $F[x]/(f(x))$ is a field if and only if $f(x)$ is irreducible. \\ \\
\textbf{Proposition 9.16}: Let $g(x)$ be a non-constant element of $F[x]$ and let $$g(x) = f_1(x)^{n_1} f_2(x)^{n_2} \dots f_k(x)^{n_k}$$ be its factorization into irreducibles, where the $f_i(x)$ are distinct. Then we have the following isomorphism of rings: $$F[x]/(g(x)) \cong F[x]/(f_1(x)^{n_1}) \times F[x]/(f_2(x)^{n_2}) \times \dots \times F[x]/(f_k(x)^{n_k}).$$ \\
\textbf{Proposition 9.17}: If the polynomial $f(x)$ has roots $\alpha_1, \alpha_2, \dots, \alpha_k \in F$ (not necessarily distinct), then $f(x)$ has $(x - a_1) \dots (x - a_k)$ as a factor. In particular, a polynomial of degree $n$ in one variable over a field $F$ has at most $n$ roots in $F$, even counted with multiplicity. \\ \\
\textbf{Proposition 9.18}: A finite subgroup of the multiplicative group of a field is cyclic. In particular, if $F$ is a finite field, then the multiplicative group $F^\times$ of nonzero elements of $F$ is a cyclic group. \\ \\
\textbf{Corollary 9.19}: Let $p$ be a prime. The multiplicative group $(\Z/p\Z)^\times$ of nonzero residue
classes mod $p$ is cyclic. \\ \\
\textbf{Corollary 9.20}: Let $n \geq 2$ be an integer with factorization $n = p_1^{\alpha_1}p_2^{\alpha_2}\dots  p_r^{\alpha_r} \in \Z$, where $p_1, \dots, p_r$ are distinct primes. We have the following isomorphisms of (multiplicative) groups: \begin{enumerate}
    \item $(\Z/n\Z)^\times \cong (\Z/p_1^{\alpha_1}\Z)^\times \times (\Z/p_2^{\alpha_2}\Z)^\times \times \dots \times (\Z/p_r^{\alpha_r}\Z)^\times$.
    \item $(\Z/2^r\Z)^\times$ is the direct product of a cyclic group of order 2 and a cyclic group of order $2^{\alpha - 2}$, for all $\alpha \geq 2.$
    \item $(\Z/p^r\Z)^\times$ is a cyclic group of order $p^{\alpha - 1}(p - 1)$, for all odd primes $p$.
\end{enumerate} $ $
\subsection*{13. Field Theory}
Recall that a field $F$ is a commutative ring with identity in which every nonzero element has an inverse. Equivalently, the set $F^\times = F - \{0\}$ of nonzero elements of $F$ is an abelian group under multiplication. \\ \\
\textbf{Definition - Characteristic}: The \textit{characteristic} of a field $F$, denoted $\ch(F)$, is defined to be the smallest positive integer $p$ such that $p \cdot 1_F = 1_F + \dots + 1_F = 0$ if such a $p$ exists, and is defined to be 0 otherwise. \\ \\
The characteristic of a field is either a prime $p$ or 0. \\ \\
\textbf{Proposition 13.1}: The characteristic of a field $F$, $\ch(F)$, is either $0$ or a prime $p$. If $\ch(F) = p$ then for any $\alpha \in F$, $$p \cdot \alpha = \alpha + \dots + \alpha = 0.$$ \\
\textbf{Definition - $\F_p, \F_p(x)$}: We define $\F_p = \Z/p\Z$ and $\F_p(x)$, the field of rational functions in $x$ with coefficients in $\F_p$. \\ \\
\textbf{Definition - Prime Subfield}: The \textit{prime subfield} of a field $F$ is the subfield of $F$ generated by the multiplicative identity $1_F$ of $F$. It is (isomorphic to) either $\Q$ (if $\ch(F) = 0$) or $\F_p$ (if $ch(F) = p$). \\ \\
This can be proved by considering a map $\varphi: \Z \rightarrow F$ in which $n \mapsto n \cdot 1_F$ and considering $\ker(\varphi) = \ch(F)\Z$. \\ \\
If a field has characteristic $p$, then $0 = p \cdot 1 = p$. \\ \\
\textbf{Definition - Extension (Field), Base Field}: If $K$ is a field containing the subfield $F$, then $K$ is said to be an \textit{extension field} (or simply an \textit{extension}) of $F$, denoted $K / F$ (which reads ``$K$ over $F$'') or by the diagram \vspace{-4mm} \begin{figure}[H]
\begin{center}
\includegraphics[scale=0.4]{def13.1.png}
\end{center}
\end{figure} \vspace{-7mm} \noindent In particular, every field $F$ is an extension of its prime subfield. The field $F$ is sometimes called the \textit{base field} of the extension. \\ \\
If $K/F$ is any extension of fields, then the multiplication defined in $K$ makes $K$ into a vector space over $F$. In particular, every field $F$ can be considered as a vector
space over its prime field. \\ \\
\textbf{Definition - (Relative) Degree/Index}: The \textit{degree} (or \textit{relative degree} or \textit{index}) of a field extension $K/F$, denoted
$[K : F]$, is the dimension of $K$ as a vector space over $F$ (i.e., $[K : F] = \dim_F K$). The extension is said to be finite if $[K : F]$ is finite and is said to be infinite otherwise. \\ \\
\textbf{Proposition 13.2}: Let $\varphi: F \rightarrow F'$ be a homomorphism of fields. Then $\varphi$ is either identically $0$ or is injective, so that the image of $\varphi$ is either $0$ or isomorphic to $F$. \\ \\
\textbf{Theorem 13.3}: Let $F$ be a field and let $p(x) \in F[x]$ be an irreducible polynomial. Then there exists a field $K$ containing an isomorphic copy of $F$ in which $p(x)$ has a root. Identifying $F$ with this isomorphic copy shows that there exists an extension of $F$ in which $p(x)$ has a root. \\ \\
\textbf{Theorem 13.4}: Let $p(x) \in F[x]$ be an irreducible polynomial of degree $n$ over the field $F$ and let $K = F[x]/(p(x))$. Let $\theta = x \text{ mod} (p(x)) \in K$. Then the elements $$1, \theta, \theta^2, \dots, \theta^{n - 1}$$ are a basis for $K$ as a vector space over $F$, so the degree of the extension is $n$, i.e., $[K : F] = n$. Hence $$K = \{a_0 + a_1\theta + \dots + a_{n - 1}\theta^{n - 1}|a_0, a_1, \dots, a_{n - 1} \in F\}$$ consists of all polynomials of degree $< n$ in $\theta$. \\ \\
\textbf{Corollary 13.5}. Let $K$ be as in Theorem 4, and let $a(\theta), b(\theta) \in K$ be two polynomials of degree $< n$ in $\theta$. Then addition in $K$ is defined simply by usual polynomial addition and multiplication in $K$ is defined by $$a(\theta)b(\theta) = r(\theta)$$ where $r(\theta)$ is the remainder (of degree $< n$) obtained after dividing the polynomial $a(x)b(x)$ by $p(x)$ in $F[x]$. \\ \\
$K$ is a field. \\ \\
\textbf{Definition - Field Generated By}: Let $K$ be an extension of the field $F$ and let $\alpha, \beta, \dots \in K$ be a collection of elements of $K$. Then the smallest subfield of $K$ containing both $F$ and the elements $\alpha, \beta, \dots$ denoted $F(\alpha, \beta, \dots)$ is called the field \textit{generated by} $\alpha, \beta, \dots$ over $F$. \\ \\
\textbf{Definition - Simple Extension, Primitive Element}: If the field $K$ is generated by a single element $\alpha$ over $F$, $K = F(\alpha)$, then $K$ is said to be a \textit{simple extension} of $F$ and the element $\alpha$ is called a \textit{primitive element} for the extension. \\ \\
\textbf{Theorem 13.6}: Let $F$ be a field and let $p(x) \in F[x]$ be an irreducible polynomial. Suppose
$K$ is an extension field of $F$ containing a root $\alpha$ of $p(x): p(\alpha) = 0$. Let $F(\alpha)$ denote the subfield of $K$ generated over $F$ by $\alpha$. Then $$F(\alpha) \cong F[x]/(p(x)).$$ \\
\textbf{Corollary 13.7}: Suppose in Theorem 6 that p(x) is of degree n. Then $$F(\alpha) = \{a_0 + a_1\alpha + a_2\alpha^2 + \dots + a_{n - 1}\alpha^{n - 1} | a_0, a_1, \dots, a_{n - 1} \in F\} \subseteq K.$$ \\
\textbf{Theorem 13.8}: Let $\varphi : F \xrightarrow{\sim} F'$ be an isomorphism of fields. Let $p(x) \in F[x]$ be an irreducible polynomial and let $p'(x) \in F'[x]$ be the irreducible polynomial obtained by applying the map $\varphi$ to the coefficients of $p(x)$. Let $\alpha$ be a root of $p(x)$ (in some extension of $F$) and let $\beta$ be a root of $p'(x)$ (in some extension of $F'$). Then there is an isomorphism \begin{align*}
    \sigma: F(\alpha) &\xrightarrow{\sim} F'(\beta) \\ 
    \alpha &\mapsto \beta
\end{align*} mapping $\alpha$ to $\beta$ and extending $\varphi$, i.e., such that $\sigma$ restricted to $F$ is the isomorphism $\varphi$. \\ \\
\textbf{Definition - Algebraic, transcendental}: Let $F$ be a field and $K$ an extension of $F$. The element $\alpha \in K$ is said to be \textit{algebraic} over $F$ if $\alpha$ is a root of some nonzero polynomial $f(x) \in F[x]$. If $\alpha$ is not algebraic over $F$ (i.e., is not the root of any nonzero polynomial with coefficients in $F$) then $\alpha$ is said to be transcendental over $F$. The extension $K / F$ is said to be \textit{algebraic} if every element of $K$ is algebraic over $F$. \\ \\
\textbf{Proposition 13.9}: Let $\alpha$ be algebraic over $F$. Then there is a unique monic irreducible polynomial $m_{\alpha, F}(x) \in F[x]$ which has $\alpha$ as a root. A polynomial $f(x) \in F[x]$ has $\alpha$ as a root if and only if $m_{\alpha, F}(x)$ divides $f(x)$ in $F[x]$. \\ \\
\textbf{Corollary 13.10}: If $L/F$ is an extension of fields and $\alpha$ is algebraic over both $F$ and $L$, then $m_{\alpha, L}(x)$ divides $m_{\alpha, F}(x)$ in $L[x]$. \\ \\
\textbf{Definition - Minimal Polynomial, Degree}: The polynomial $m_{\alpha, F}(x)$ (or just $m_\alpha(x)$ if the field $F$ is understood) in Proposition 9 is called the \textit{minimal polynomial} for $\alpha$ over $F$. The degree of $m_\alpha(x)$ is called the \textit{degree} of $\alpha$. \\ \\
\textbf{Proposition 13.11}: Let $\alpha$ be algebraic over the field $F$ and let $F(\alpha)$ be the field generated
by $\alpha$ over $F$. Then $$F(\alpha) \cong F[x]/(m_\alpha(x))$$ so that in particular $$[F(\alpha) : F] = \deg{m_\alpha(x)} = \deg{\alpha},$$ i.e., the degree of $\alpha$ over $F$ is the degree of the extension it generates over $F$. \\ \\
\textbf{Proposition 13.12}: The element $\alpha$ is algebraic over $F$ if and only if the simple extension
$F(\alpha) / F$ is finite. More precisely, if $\alpha$ is an element of an extension of degree $n$ over $F$ then $\alpha$ satisfies a polynomial of degree at most $n$ over $F$ and if $\alpha$ satisfies a polynomial of degree $n$ over $F$ then the degree of $F(\alpha)$ over $F$ is at most $n$. \\ \\
\textbf{Corollary 13.13}: If the extension $K / F$ is finite, then it is algebraic. \\ \\
\textbf{Theorem 13.14}: Let $F \subseteq K \subseteq L$ be fields. Then $$[L : F] = [L : K][K : F],$$ i.e. extension degrees are multiplicative, where if one side of the equation is infinite, the other side is also infinite. \\ \\
\textbf{Corollary 13.15}: Suppose $L/ F$ is a finite extension and let $K$ be any subfield of $L$ containing $F, F \subseteq K \subseteq L$. Then $[K : F]$ divides $[L : F]$. \\ \\
\textbf{Definition - Finitely Generated}: An extension $K / F$ is \textit{finitely generated} if there are elements $\alpha_1, \dots, \alpha_k$ in $K$ such that $K = F(\alpha_1, \dots, \alpha_k)$. \\ \\
\textbf{Lemma 13.16}: $F(\alpha, \beta) = (F(\alpha))(\beta)$, i.e., the field generated over $F$ by $\alpha$ and $\beta$ is the field generated by $\beta$ over the field $F(\alpha)$ generated by $\alpha$. \\ \\
\textbf{Theorem 13.17}: The extension $K / F$ is finite if and only if $K$ is generated by a finite number of algebraic elements over $F$. More precisely, a field generated over $F$ by a finite number of algebraic elements of degrees $n_1, n_2, \dots, n_k$ is algebraic of degree $\leq n_1 n_2 \dots n_k$. \\ \\
\textbf{Corollary 13.18}: Suppose $\alpha$ and $\beta$ are algebraic over $F$. Then $\alpha \pm \beta$, $\alpha \beta$, $\alpha / \beta$ (for $\beta \neq 0$), (in particular $\alpha^{-1}$ for $\alpha \neq 0$) are all algebraic. \\ \\
\textbf{Corollary 13.19}: Let $L/ F$ be an arbitrary extension. Then the collection of elements of $L$ that are algebraic over $F$ form a subfield $K$ of $L$. \\ \\
\textbf{Theorem 13.20}: If $K$ is algebraic over $F$ and $L$ is algebraic over $K$, then $L$ is algebraic over $F$. \\ \\
\textbf{Definition - Composite Field}: Let $K_1$ and $K_2$ be two subfields of a field $K$. Then the \textit{composite field} of $K_1$ and $K_2$, denoted $K_1 K_2$, is the smallest subfield of $K$ containing both $K_1$ and $K_2$. Similarly, the composite of any collection of subfields of $K$ is the smallest subfield containing all the subfields. \\ \\
Note that the composite field $K_1K_2$ can also be defined as the intersection of all the subfields of $K$ containing both $K_1$ and $K_2$. \\ \\
\textbf{Proposition 13.21}: Let $K_1$ and $K_2$ be two finite extensions of a field $F$ contained in $K$. Then $$[K_1 K_2 : F] \leq [K_1 : F][K_2 : F]$$ with equality if and only if an $F$-basis for one of the fields remains linearly independent over the other field. In other words, if $\alpha_1, \alpha_2, \dots, \alpha_n$ and $\beta_1, \beta_2, \dots, \beta_m$ are bases for $K_1$ and $K_2$ over $F$, respectively, then the elements $\alpha_i \beta_j$ for $i = 1, 2, \dots, n$ and $j = 1, 2, \dots, m$ span $K_1 K_2$ over $F$. \\ \\
\textbf{Corollary 13.22}: Suppose that $[K_1 : F] = n, [K_2 : F] = m$ in Proposition 21, where $(m, n) = 1$, i.e. $m, n$ are relatively prime. Then $[K_1 K_2 : F] = [K_1 : F][K_2 : F] = mn$. \\ \\
\textbf{Proposition 13.23}: If the element $\alpha \in \R$ is obtained from a field $F \subset \R$ by a (finite) series of compass and straightedge constructions then $[F(\alpha) : F] = 2^k$ for some integer $k \geq 0$. \\ \\
\textbf{Theorem 13.24}: None of the classical Greek problems: \begin{enumerate}[(I)]
    \item Doubling/Duplicating of the Cube, 
    \item Trisecting an Angle, and 
    \item Squaring the Circle,
\end{enumerate} are possible. \\ \\
Note that the distinction between a ``straight-edge'' and ruler is very important. Given a ruler with unit length 1 marked and a unit compass, it would be possible to trisect a given angle. Similarly is true of doubling the cube. \\ \\
\textbf{Definition - Splitting Field, Splits Completely}: The extension field $K$ of $F$ is called a \textit{splitting field} for the polynomial $f(x) \in F[x]$ if $f(x)$ factors completely into linear factors (or \textit{splits completely}) in $K[x]$ and $f(x)$ does not factor completely into linear factors over any proper subfield of $K$ containing $F$. \\ \\
\textbf{Theorem 13.25}: For any field $F$, if $f(x) \in F[x]$ then there exists an extension $K$ of $F$ which is a splitting field for $f(x)$. \\ \\
\textbf{Definition - Normal Extension}: If $K$ is an algebraic extension of $F$ which is the splitting field over $F$ for a collection of polynomials $f(x) \in F[x]$ then $K$ is called a \textit{normal extension} of $F$. \\ \\
\textbf{Proposition 13.26}: A splitting field of a polynomial of degree $n$ over $F$ is of degree at most $n!$ over $F$. \\ \\
\textbf{Definition - Primitive $n$th Root of Unity}: A generator of the cyclic group of all $n$th roots of unity is called a \textit{primitive $n$th root of unity}. \\ \\
Define $\zeta_n$ to be the first $n$th root of unity (counting counterclockwise from 1). \\ \\
\textbf{Definition - Cyclotomic Field of $n$th Roots of Unity}: The field $\Q(\zeta_n)$ is called the \textit{cyclotomic field of $n$th roots of unity}. \\ \\
\textbf{Theorem 13.27}: Let $\varphi: F \xrightarrow{\sim} F'$ be an isomorphism of fields. Let $f(x) \in F[x]$ be a polynomial and let $f'(x) \in F'[x]$ be the polynomial obtained by applying $\varphi$ to the coefficients of $f(x)$. Let $E$ be a splitting field for $f(x)$ over $F$ and let $E'$ be a splitting field for $f'(x)$ over $F'$. Then the isomorphism $\varphi$ extends to an isomorphism $\sigma: E \xrightarrow{\sim} E'$, i.e., $\sigma$ restricted to $F$ is the isomorphism $\varphi:$ \begin{alignat*}{2}
    \sigma : \quad &E \quad \xrightarrow{\sim} \quad &&E' \\
    &| &&| \\
    \varphi : \quad &F \quad \xrightarrow{\sim} &&F'
\end{alignat*} $ $ \\
\textbf{Corollary 13.28 - Uniqueness of Splitting Fields}: Any two splitting fields for a polynomial $f(x) \in F[x]$ over a field $F$ are isomorphic. \\ \\
\textbf{Definition - Algebraic Closure}: The field $\overline{F}$ is called an \textit{algebraic closure} of $F$ if $\overline{F}$ is algebraic over $F$ and if every polynomial $f(x) \in F[x]$ splits completely over $\overline{F}$ (so that $\overline{F}$ can be said to contain all the elements algebraic over $F$). \\ \\
\textbf{Definition - Algebraically Closed}: A field $K$ is said to be \textit{algebraically closed} if every polynomial with coefficients in $K$ has a root in $K$. \\ \\
$K = \overline{K}$ iff $K$ is algebraically closed. This also means that $\overline{\overline{K}} = \overline{K}$, for any field $K$. \\ \\
\textbf{Proposition 13.29}: Let $\overline{F}$ be an algebraic closure of $F$. Then $\overline{F}$ is algebraically closed. \\ \\
\textbf{Proposition 13.30}: For any field $F$ there exists an algebraically closed field $K$ containing $F$. \\ \\
\textbf{Proposition 13.31}: Let $K$ be an algebraically closed field and let $F$ be a subfield of $K$. Then the collection of elements $\overline{F}$ of $K$ that are algebraic over $F$ is an algebraic closure of $F$. An algebraic closure of $F$ is unique up to isomorphism. \\ \\
\textbf{Theorem - Fundamental Theorem of Algebra}: The field $\C$ is algebraically closed. \\ \\
\textbf{Corollary 13.32}: The field $\C$ contains an algebraic closure for any of its subfields. In particular, $\overline{\Q}$, the collection of complex numbers algebraic over $\Q$, is an algebraic closure of $\Q$. \\ \\
\textbf{Definition - Separable, Inseparable}: A polynomial over $F$ is called \textit{separable} if it has no multiple roots (i.e., all its roots are distinct). A polynomial which is not separable is called \textit{inseparable}. \\ \\
By technicality of the definition, if a polynomial has no roots, e.g. a constant polynomial, then it is separable. \\ \\
\textbf{Definition - Derivative}: The \textit{derivative} of the polynomial $$f(x) = a_n x^n + a_{n - 1}x^{n - 1} + \dots + a_1x + a_0 \in F[x]$$ is defined to be the polynomial $$D_x f(x) = na_n x^{n - 1} + (n - 1)a_{n - 1}x^{n - 2} + \dots + a_1\in F[x].$$ \\
Note that while this is defined similarly to that of analysis, if $F$ is a discrete field, then the analytic notion of derivatives defined using limits (which are continuous) may not exist. \\ \\
\textbf{Proposition 13.33}: A polynomial $f(x)$ has a multiple root $\alpha$ if and only if $\alpha$ is also a root of $D_x f(x)$, i.e., $f(x)$ and $D_x f(x)$ are both divisible by the minimal polynomial for $\alpha$. In particular, $f(x)$ is separable if and only if it is relatively prime to its derivative: $(f(x), D_x f(x)) = 1$. \\ \\
\textbf{Corollary 13.34}: Every irreducible polynomial over a field of characteristic 0 (for example, $\Q$) is separable. A polynomial over such a field is separable if and only if it is the product of distinct irreducible polynomials. \\ \\
\textbf{Proposition 13.35}: Let $F$ be a field of characteristic $p$. Then for any $a, b \in F$, $$(a + b)^p = a^p + b^p, \text{ and } (ab)^p = a^p b^p.$$ Put another way, the $p$th-power map defined by $\varphi(a) = a^p$ is an injective field homomorphism from $F$ to $F$. If $F$ is finite, then $\varphi$ is an isomorphism. \\ \\
\textbf{Definition - Frobenius Endomorphism}: The map in Proposition 13.35 is called the \textit{Frobenius endomorphism} of $F$. \\ \\
\textbf{Corollary 13.36}: Suppose that $\F$ is a finite field of characteristic $p$. Then every element
of $\F$ is a $p$th power in $\F$ (notationally, $\F = \F^p$). \\ \\
\textbf{Proposition 13.37}: Every irreducible polynomial over a finite field $\F$ is separable. A polynomial in $\F[x]$ is separable if and only if it is the product of distinct irreducible polynomials in $\F[x]$. \\ \\
\textbf{Definition - Perfect}: A field $K$ of characteristic $p$ is called \textit{perfect} if every element of $K$ is a $p$th power in $K$, i.e., $K = K^P$. Any field of characteristic 0 is also called \textit{perfect}. \\ \\
\textbf{Definition - $\F_{p^n}$}: For any integer $n > 0$, finite fields of any order $p^n$ exist, for prime $p$, and are unique up to isomorphism. This field is denoted $\F_{p^n}$ and can be constructed as the splitting field of the equation $x^{p^n} - x$ over $\F_p,$ the field of integers modulo $p.$ \\ \\
\textbf{Proposition 13.38}: Let $p(x)$ be an irreducible polynomial over a field $F$ of characteristic $p$. Then there is a unique integer $k \geq 0$ and a unique irreducible separable polynomial $p_{sep}(x) \in F[x]$ such that $$p(x) = p_{sep} \left( x^{p^k} \right) .$$ \\
\textbf{Definition - (In)Separable Degree}: Let $p(x)$ be an irreducible polynomial over a field of characteristic $p$. The degree of $p_{sep}(x)$ in proposition 13.38 is called the \textit{separable degree} of $p(x)$, denoted $\deg_s p(x)$. The integer $p^k$ in the proposition is called the \textit{inseparable degree} of $p(x)$, denoted $\deg_i p(x)$. \\ \\
Then a new definition for $p(x)$ is separable arises, being that the inseparable degree of $p$ is 1, which is also equivalent to the separable degree being equal to the degree of $p$. Additionally, by definition, $\deg p(x) = \deg_s p(x) \deg_i p(x).$ \\ \\
\textbf{Definition - Separably Algebraic}: The field $K$ is said to be \textit{separable} (or \textit{separably algebraic}) over $F$ if every element of $K$ is the root of a separable polynomial over $F$ (equivalently, the minimal polynomial over $F$ of every element of $K$ is separable). A field which is not separable is inseparable. \\ \\
\textbf{Corollary 13.39}: Every finite extension of a perfect field is separable. In particular, every finite extension of either $\Q$ or a finite field is separable.
\subsection*{10. Introduction to Module Theory}
\textbf{Definition - Left Module Over $R$, Unital Modules}: Let $R$ be a ring (not necessarily commutative nor with $1$). A \textit{left $R$-module} or a \textit{left module over $R$} is a set $M$ together with \begin{enumerate}
    \item a binary operation $+$ on $M$ under which $M$ is an abelian group, and
    \item an action of $R$ on $M$ (that is, a map $R \times M \rightarrow M$) denoted by $rm$, for all $r \in R$ and for all $m \in M$ which satisfies the following for all $r, s \in R$, and $m, n \in M$ \begin{enumerate}
        \item $(r + s)m = rm + sm$
        \item $(rs)m = r(sm)$
        \item $r(m + n) = rm + rn$
    \end{enumerate} If $R$ has identity 1, then we impose an additional axiom that \begin{enumerate}
        \item[(d)] $1m = m$. Modules satisfying this axiom are called \textit{unital modules}.
    \end{enumerate}
\end{enumerate} The notion of a right module could be defined similarly. If $R$ is commutative, for a left $R$-module $M$, we could make $M$ a right module by defining $mr = rm$, for all $r \in R, m \in M$. Not every left $R$-module is a right $R$-module. \\ \\
Unless explicitly mentioned, a ``module'' will always refer to a left module. Additionally, we consider only unital modules, to avoid pathology. \\ \\
When $R$ is a field, the axioms of a module are exactly that of a vector space, so modules over a field $F$ and vector spaces over $F$ are the same. \\ \\
\textbf{Definition - $R$-Submodule}: Let $R$ be a ring and let $M$ be an $R$-module. An \textit{$R$-submodule} of $M$ is a subgroup $N$ of $M$ which is closed under the action of ring elements, i.e., $rn \in N$, for all $r \in R, n \in N$. Every module $M$ has at least 2 submodules, 0, the \textit{trivial submodule}, and itself. \\ \\
\textbf{Definition - Free Module of Rank $n$ over $R$}: Define $$R^n = \{(r_1, r_2, \dots, r_n) | r_i \in R, \text{ for }i = [n]\}.$$ Then we can make $R^n$ an $R$-module by defining addition component-wise and scalar multiplication by an element of $R$ also component-wise. We call $R^n$ the \textit{free module of rank $n$ over $R$}. \\ \\
\textbf{Definition - Annihilated by}:  If $M$ is an $R$-module and for some (2-sided) ideal $I$ of $R$, $im = 0$, for all $i \in I$ and all $m \in M$, we say $M$ is \textit{annihilated by} $I$. In this case, a very natural next step is to make $M$ into a $(R/I)$-module by defining 
$(r + I)m = rm$, for coset $r + I$ in $R/I$ and $m \in M$. \\ \\
\textbf{Example - $\Z$-Modules}: For $R = \Z$ and $A$ being any Abelian group (where we write the operation of $A$ as $+$), we can make $A$ into a $\Z$-module by defining the action of $n \in \Z$ on $a \in A$ as $$na = \begin{cases}
    a + a + \dots + a, & \text{ if } n > 0 \\
    0, & \text{ if } n = 0 \\
    -a - a - \dots - a, & \text{ if } n < 0
\end{cases},$$ here 0 is identity of the additive group $A$. Thus, every Abelian group $A$ is a $\Z$-module. The converse that every $\Z$-module $M$ is an Abelian group is also true, so $\Z$-modules are the same as abelian groups. \\ \\
\textbf{Definition - Shift Operator}: Let $V$ be an affine $n$-space $F^n$ and let $T$ be the \textit{shift operator}, where $$T(x_1, x_2, \dots, x_n) = (x_2, x_3, \dots, x_n, 0).$$ \\
\textbf{Definition - $F[x]$-Modules, $T$-Stable/Invariant}: Let $F$ be a field, $V$ be a vector space over $F$, $x$ an indeterminate, and $T$ a linear transformation from $V$ to $V$. Then we can  make $V$ a $F[x]$-module by defining the action of $p(x) = a_nx^n + \dots + a_1x + a_0 \in F[X]$, for $a_i \in F$, on $v \in V$ by $$p(T)(v) = a_n T^n(v) + \dots + a_1 T(v) + a_0,$$ which clearly satisfies the module axioms. Any vector subspace $U \subseteq V$ such that $T(U) \subseteq U$ is called \textit{$T$-stable} or \textit{$T$-invariant}. \\ \\
Additionally, there exists a bijection between \{$V$ a $F[x]$-module\} and $V$ a vector space over $F$ and $T: V \rightarrow V$ a linear transformation. Similarly, there exists a bijection between \{$W$ a $F[x]$-submodule\} and $W$ a subspace of $V$ and $W$ is $T$-stable. \\ \\
\textbf{Proposition 10.1 - The Submodule Criterion}: Let $R$ be a ring and let $M$ be an $R$-module. A subset $N$ of $M$ is a submodule of $M$ if and only if \begin{enumerate}
    \item $N \neq \emptyset$, and
    \item $x + ry \in N$, for all $r \in R$ and $x, y \in N$.
\end{enumerate} $ $ \\
\textbf{Definition - $R$-Algebra}: Let $R$ be a commutative ring with identity. An \textit{$R$-algebra} is a ring $A$ with identity together with a ring homomorphism $f: R \rightarrow A$ mapping $1_R$ to $1_A$ such that the subring $f(R)$ of $A$ is contained in the center of $A$. \\ \\
\textbf{Definition - $R$-Algebra Homomorphism}: If $A$ and $B$ are two $R$-algebras, an \textit{$R$-algebra homomorphism} (or \textit{isomorphism}) is a ring homomorphism (isomorphism, respectively) $\varphi: A \rightarrow B$ mapping $1_A$ to $1_B$ such that $\varphi(r \cdot a) = r \cdot \varphi(a)$ for all $r \in R$ and $a \in A$. \\ \\
\textbf{Definition - $R$-Module Homomorphism, Isomorphism, Kernel}: Let $R$ be a ring and let $M$ and $N$ be $R$-modules. \begin{enumerate}
    \item A map $\varphi: M \rightarrow N$ is an \textit{$R$-module homomorphism} if it respects the $R$-module structures of $M$ and $N$, i.e \begin{enumerate}
        \item $\varphi(x + y) = \varphi(x) + \varphi(y)$, for all $x, y \in M$, and
        \item $\varphi(rx) = r\varphi(x)$, for all $r \in R, x \in M$.
    \end{enumerate}
    \item An $R$-module homomorphism is an \textit{isomorphism} (of $R$-modules) if it is both injective and surjective. The modules $M$ and $N$ are said to be isomorphic, denoted $M \cong N$, if there is some $R$-module isomorphism $\varphi: M \rightarrow N$.
    \item If $\varphi: M \rightarrow N$ is an $R$-module homomorphism, let $\ker \varphi = \{ m \in M | \varphi(m) = 0\}$ (the \textit{kernel} of $\varphi$) and let $\varphi(M) = \{n \in N | n = \varphi(m) \text{ for some } m \in M\}$ (the image of $\varphi$, as usual).
    \item Let $M$ and $N$ be $R$-modules and define $\hom_R(M, N)$ to be the set of all $R$-module homomorphisms from $M$ into $N$.
\end{enumerate} $ $ \\
An immediate corollary is that every $R$-module homomorphism is a homomorphism of the underlying additive groups. Additionally, kernels and images of $R$-modules are submodules. Additionally, when $R$ is a field, $R$-module homomorphisms are called linear transformations. \\ \\
\textbf{Proposition 10.2}: Let $M, N$ and $L$ be $R$-modules. \begin{enumerate}
    \item A map $\varphi: M \rightarrow N$ is an $R$-module homomorphism if and only if $\varphi(rx + y) = r\varphi(x) + \varphi(y)$ for all $x, y \in M$ and all $r \in R$.
    \item Let $\varphi, \psi$ be  elements of $\hom_R(M, N)$. Define $\varphi + \psi$ by $$(\varphi + \psi)(m) = \varphi(m) + \psi(m), \text{ for all } m \in M.$$ Then $\varphi + \psi \in \hom_R(M, N)$ and with this operation $\hom_R(M, N)$ is an abelian group under addition. If $R$ is a commutative ring then for $r \in R$ define $r\varphi$ by $$(r\varphi)(m) = r(\varphi(m)), \text{ for all } m \in M.$$ Then $r\varphi \in \hom_R(M, N)$ and with this action of the commutative ring $R$ the abelian group $\hom_R(M, N)$ is an $R$-module.
    \item If $\varphi \in \hom_R(L, M)$ and $\psi \in \hom_R(M, N)$, then $\psi \circ \varphi \in \hom_R(L, N)$.
    \item With addition as above and multiplication defined as function composition, $\hom_R(M, M)$ is a ring with 1. When $R$ is commutative $\hom_R(M, M)$ is an $R$-algebra.
\end{enumerate} $ $ \\
\textbf{Definition - Endomorphism Ring, Endomorphism}: The ring $\hom_R(M, M)$ is called the \textit{endomorphism ring of $M$} and will often be denoted by $\End_R(M)$, or just $\End(M)$ when the ring $R$ is clear from the context. Elements of $\End(M)$ are called \textit{endomorphisms}. \\ \\
\textbf{Proposition 10.3}: Let $R$ be a ring, let $M$ be an $R$-module and let $N$ be a submodule of $M$. The (additive, abelian) quotient group $M / N$ can be made into an $R$-module by defining an action of elements of $R$ by $$r(x + N) = (rx) + N, \text{ for all } r \in R, x + N \in M/N.$$ The natural projection map $\pi: M \rightarrow M/N$ defined by $\pi(x) = x + N$ is an $R$-module homomorphism with kernel $N$. \\ \\
\textbf{Definition - Sum of Modules}: Let $A, B$ be submodules of the $R$-module $M$. The \textit{sum} of $A$ and $B$ is the set $A + B = \{a + b | a \in A, b \in B\}$. \\ \\
\textbf{Theorem 10.4 - Isomorphism Theorems}: \begin{enumerate}
    \item (\textit{The First Isomorphism Theorem for Modules}) Let $M, N$ be $R$-modules and let $\varphi: M \rightarrow N$ be an $R$-module homomorphism. Then $\ker \varphi$ is a submodule of $M$ and $M/\ker \varphi \cong \varphi(M)$. 
    \item (\textit{The Second Isomorphism Theorem}) Let $A, B$ be submodules of the $R$-module $M$. Then $(A + B)/B \cong A/(A \cap B)$. 
    \item (\textit{The Third Isomorphism Theorem}) Let $M$ be an $R$-module, and let $A$ and $B$ be submodules of $M$ with $A \subseteq B$. Then $(M/A)/(B/A) \cong M/B$.
    \item (\textit{The Fourth or Lattice Isomorphism Theorem}) Let $N$ be a submodule of the $R$-module $M$. There is a bijection between the submodules of $M$ which contain $N$ and the submodules of $M/N$. The correspondence is given by $A \leftrightarrow A/N$, for all $A \supseteq N$. This correspondence commutes with the processes of taking sums and intersections (i.e., is a lattice isomorphism between the lattice of submodules of $M / N$ and the lattice of submodules of $M$ which contain $N$). 
\end{enumerate} $ $ \\
\textbf{Definition - Finite Sums, (Finitely) Generated by, Minimal, Cyclic}: Let $M$ be an $R$-module and let $N_1, \dots, N_n$ be submodules of $M$. \begin{enumerate}
    \item The \textit{sum} of $N_1, \dots, N_n$ is the set of all finite sums of elements from the sets $N_i$, i.e. $\{a_1 + a_2 + \dots + a_n | a_i \in N_i, \text{ for all } i\}$. Denote this sum by $N_1 + \dots + N_n$.
    \item For any subset $A$ of $M$ let $$RA = \{r_1 a_1 + r_2 a_2 + \dots +r_ma_m | r_1, \dots, r_m \in R, a_1, \dots, a_m \in A, m \in \Z^+\}$$ (where by convention $RA = \{0\}$ if $A = \emptyset$). If $A$ is the finite set $\{a_1 , a_2, \dots, a_n\}$ we shall write $Ra_1 + Ra_2 + \dots + Ra_n$ for $RA$. Call \textit{$RA$ the submodule of $M$ generated by $A$}. If $N$ is a submodule of $M$ (possibly $N = M$) and $N = RA$, for some subset $A$ of $M$, we call $A$ a \textit{set of generators} or \textit{generating set} for $N$, and we say $N$ is \textit{generated} by $A$.
    \item A submodule $N$ of $M$ (possibly $N = M$) is \textit{finitely generated} if there is some finite subset $A$ of $M$ such that $N = RA$, that is, if $N$ is generated by some finite subset. Additionally, if $N$ if finitely generated, then there exists a smallest integer $d > 0$ such that $N$ is generated by some set of $d$ elements. \\ \\
    Any generating set consisting of $d$ elements will be called a \textit{minimal set of generators} for $N$ (this minimal set will not be unique in general).
    \item A submodule $N$ of $M$ (possibly $N = M$) is \textit{cyclic} if there exists an element $a \in M$ such that $N = Ra$, that is, if $N$ is generated by one element, i.e. $N = Ra = \{ra | r \in R\}$. 
\end{enumerate} $ $ \\
$RA$ is a submodule of $M$ and is, in fact, the smallest submodule of $M$ which contains $A$. \\ \\
\textbf{Definition - Direct Product/External Direct Sum}: Let $M_1, \dots, M_k$ be a collection of $R$-modules. The collection of $k$-tuples
$(m_1, m_2, \dots, m_k)$ where $m_i \in M_i$ with addition and action of $R$ defined component-wise is called the \textit{direct product} of $M_1, \dots, M_k$, denoted $M_1 \times \dots \times M_k$. A direct product of $R$-modules may also sometimes be referred to as the \textit{external direct sum} of $M_1, \dots, M_k$. \\ \\
\textbf{Proposition 10.5 - Internal Direct Sum}: Let $N_1, N_2, \dots, N_k$ be submodules of the $R$-module $M$. Then the following are equivalent: \begin{enumerate}
    \item The map $\pi: N_1 \times N_2 \times \dots \times N_k \rightarrow N_1 + N_2 + \dots + N_k$ defined by $$\pi(a_1, a_2, \dots, a_k) = a_1 + a_2 + \dots + a_k$$ is an isomorphism (of $R$-modules): $N_1 + N_2 + \dots + N_k \cong N_1 \times N_2 \times \dots \times N_k$.
    \item $N_j \cap (N_1 + N_2 + \dots + N_{j - 1} + N_{j + 1} + \dots + N_k) = 0$, for all $j \in [k]$.
    \item Every $x \in N_1 + N_2 + \dots + N_k$ can be written uniquely in the form $a_1 + a_2 + \dots + a_k$ with $a_i \in N_i$.
\end{enumerate} If $M = N_1 + N_2 + \dots + N_k$ satisfying condition 3 above, then $M$ is said to be the internal direct sum of $N_1, N_2, \dots, N_k$, written $$M = N_1 \oplus N_2 \oplus \dots \oplus N_k.$$ \\
\textbf{Definition - Free, Basis/Set of Free Generators, Rank}: An $R$-module $F$ is said to be \textit{free} on the subset $A$ of $F$ if for every nonzero element $x$ of $F$, there exist unique nonzero elements $r_1, r_2, \dots, r_n$ of $R$ and
unique $a_1, a_2, \dots, a_n$ in $A$ such that $x = r_1 a_1 + r_2 a_2 + \dots + r_n a_n$, for some $n \in \Z^+$. In this situation we say $A$ is a \textit{basis} or \textit{set of free generators} for $F$. If $R$ is a commutative ring the cardinality of $A$ is called the \textit{rank} of $F$. \\ \\
\textbf{Theorem 10.6}: For any set $A$ there is a free $R$-module $F(A)$ on the set $A$ and $F(A)$ satisfies the following \textit{universal property}: if $M$ is any $R$-module and $\varphi: A \rightarrow M$ is any map of sets, then there is a unique $R$-module homomorphism $\phi: F(A) \rightarrow M$ such that
$\phi(a) = \varphi(a)$, for all $a \in A$, that is, the following diagram commutes. \vspace{-4mm} \begin{figure}[H]
\begin{center}
\includegraphics[scale=0.4]{Thm10.6.png}
\end{center}
\end{figure} \vspace{-5mm} \noindent When $A$ is the finite set $\{a_1, a_2, \dots, a_n\}$, $F(A) = Ra_1 \oplus Ra_2 \oplus \dots \oplus Ra_n \cong R^n.$ \\ \\
\textbf{Corollary 10.7 - Extend by Linearity}: \begin{enumerate}
    \item If $F_1$ and $F_2$ are free modules on the same set $A$, there is a unique isomorphism between $F_1$ and $F_2$ which is the identity map on $A$.
    \item If $F$ is any free $R$-module with basis $A$, then $F \cong F(A)$. In particular, $F$ enjoys the same universal property with respect to $A$ as $F(A)$ does in Theorem 6.
\end{enumerate} We often define $R$-module homomorphisms from $F$ into other $R$-modules simply by specifying their values on the elements of $A$, then saying ``extend by linearity.'' \\ \\
When $R = \Z$, the free module on a set $A$ is called the free abelian group on $A$. If $|A| = n, F(A)$ is called the free abelian group of rank $n$ and is isomorphic to $\Z \oplus \dots \oplus \Z$ ($n$ times).
\subsubsection*{Tensor Product of Modules}
Let $R$ be a subring of a ring $S$ and $f: R \rightarrow S$ is a ring homomorphism with $f(1_R) = 1_S$. Then for some left $S$-module $N$, we can make $N$ an $R$-module if $rn = f(r)n$, for defining the action of $f(r)n = sn$, when $f(r) = s$, the same way as was defined for $N$ a left $S$-module. In this case $S$ is considered as an \textit{extension} of the ring $R$ and the resulting $R$-module is said to be obtained from $N$ by \textit{restriction of scalars} from $S$ to $R$. \\ \\
\textbf{Definition - Tensor Product}: Starting with a subring $R$ of a ring $S$ and $N$ a left $R$-module. We call $S \otimes_R N$ (or just $S \otimes N$ is $R$ is clear from context) the \textit{tensor product} of $S$ and $N$ over $R$. The elements of $S \otimes_R N$ are called \textit{tensors} and can be written as finite sums of the form $s \otimes n$ with $s \in S, n \in N$. Then $S \otimes_R N$ is naturally a left $S$-module under the action defined by $$s \left( \sum s_i \otimes n_i \right) = \sum (ss_i) \otimes n_i.$$ In this case, $S \otimes_R N$ is called the \textit{(left) $S$-module obtained by extension of scalars from the (left) $R$-module $N$}. \\ \\
Less formally, a tensor product $S \otimes_R N$ can be seen simply as an extension of the left $R$-module $N$ to an $S$-module. \\ \\
\textbf{Properties of Tensor Products}: Given a tensor product $S \otimes_R N$ (for $R$ is a subring of $S$), elements $s_1, s_2 \in S$, $n_1, n_2 \in N$, and $r \in R S$, \begin{enumerate}
    \item $(s_1 + s_2) \otimes n = s_1 \otimes n + s_2 \otimes n$,
    \item $s \otimes (n_1 + n_2) = s \otimes n_1 + s \otimes n_2$, and
    \item $sr \otimes n = s \otimes rn$.
\end{enumerate} $ $ \\
\textbf{Theorem 10.8}: Let $R$ be a subring of $S$, let $N$ be a left $R$-module and let $\iota: N \rightarrow S \otimes_R N$ be the $R$-module homomorphism defined by $\iota(n) = 1 \otimes n$. Suppose that $L$ is any left $S$-module (hence also an $R$-module) and that $\varphi: N \rightarrow L$ is an $R$-module homomorphism from $N$ to $L$. Then there is a unique $S$-module homomorphism $\phi: S \otimes_R N \rightarrow L$ such that $\varphi$ factors through $\phi$, i.e. $\varphi = \phi \circ \iota$ and the diagram \vspace{-3mm} \begin{figure}[H]
\begin{center}
\includegraphics[scale=0.4]{Thm10.8.png}
\end{center}
\end{figure} \vspace{-5mm} \noindent commutes. Conversely, if $\phi: S \otimes_R N \rightarrow L$ is an $S$-module homomorphism then $\varphi = \phi \circ i$ is an $R$-module homomorphism from $N$ to $L$. \\ \\
\textbf{Corollary 10.9}: Let $\iota: N \rightarrow S \otimes_R N$ be the $R$-module homomorphism in Theorem 8 above. Then $N/\ker{\iota}$ is the unique largest quotient of $N$ that can be embedded into any $S$-module. In particular, $N$ can be embedded as an $R$-submodule of some left $S$-module iff $\iota$ is injective (in which case $N$ is isomorphic to the $R$-submodule $\iota(N)$ of the $S$-module $S \otimes_R N$). \\ \\
\textbf{Definition - Tensor Product of Two $R$-Modules}: For a right $R$-module $M$, and left $R$-module $N$, we denote the \textit{tensor product of $M$ and $N$ over $R$}, as $M \otimes_R N$ (or $M \otimes N$) and have the following relations: \begin{align*}
    (m_1 + m_2) \otimes n &= m_1 \otimes n + m_2 \otimes n, \\
    m \otimes (n_1 + n_2) &= m \otimes n_1 + m \otimes n_2, \text{ and} \\
    mr \otimes n &= m \otimes rn.
\end{align*} The elements of $M \otimes_R N$ are called \textit{tensors}, and the coset of $(m ,n)$ in $M \otimes_R N$, $m \otimes n$, is called a \textit{simple tensor}. \\ \\
A tensor product can be understood alternatively as quotienting out by the subgroup generated by the above relations as follows: $$(m_1 + m_2) \otimes n = m_1 \otimes n + m_2 \otimes n \quad \leftrightarrow \quad (m_1 + m_2, n) - (m_1, n) - (m_2, n).$$ \\
\textbf{Definition - $R$-balanced, Middle Linear}: Let $M$ be a right $R$-module, let $N$ be a left $R$-module and let $L$ be an abelian group (written additively). A map $\varphi: M \times N \rightarrow L$ is called \textit{$R$-balanced} or \textit{middle linear with respect to $R$} if \begin{align*}
    \varphi(m_1 + m_2, n) &= \varphi(m_1, n) + \varphi(m_2, n) \\
    \varphi(m, n_1 + n_2) &= \varphi(m, n_1) + \varphi(m, n_2) \\
    \varphi(m, rn) &= \varphi(mr, n)
\end{align*} for all $m, m_1, m_2 \in M$, $n, n_1, n_2 \in N$, and $r \in R$. \\ \\
\textbf{Theorem 10.10}: Suppose $R$ is a ring with 1, $M$ is a right $R$-module, and $N$ is a left $R$-module. Let $M \otimes_R N$ be the tensor product of $M$ and $N$ over $R$ and let $\iota: M \times N \rightarrow M \otimes_R N$ be the $R$-balanced map defined above. \begin{enumerate}
    \item If $\phi: M \otimes_R N \rightarrow L$ is any group homomorphism from $M \otimes_R N$ to an abelian group $L$, then the composite map $\varphi: \phi \circ \iota$ is an $R$-balanced map from $M \times N$ to $L$.
    \item Conversely, suppose $L$ is an Abelian group and $\varphi: M \times N \rightarrow L$ is any $R$-balanced map. Then there is a unique group homomorphism $\phi: M \otimes_R N \rightarrow L$ such that $\varphi$ factors through $\iota$, i.e. $\varphi = \phi \circ \iota$ as in (1).
\end{enumerate} Equivalently,  the correspondence $\varphi \leftrightarrow \phi$ in the commutative diagram \vspace{-2mm} \begin{figure}[H]
\begin{center}
\includegraphics[scale=0.4]{Thm10.10.png}
\end{center}
\end{figure} \vspace{-7mm} \noindent establishes a bijection $$\begin{Bmatrix}
    R\text{-balanced maps} \\
    \varphi: M \times N \rightarrow L
\end{Bmatrix} \leftrightarrow \begin{Bmatrix}
    \text{group homomorphisms} \\
    \phi: M \otimes_R N \rightarrow L
\end{Bmatrix}.$$ \\
\textbf{Corollary 10.11}: Suppose $D$ is an abelian group and $\iota': M \times N \rightarrow D$ is an $R$-balanced map such that \begin{enumerate}[(i)]
    \item the image of $\iota'$ generates $D$ as an abelian group, and
    \item every $R$-balanced map defined on $M \times N$ factors through $\iota'$ as in Theorem 10.
\end{enumerate} Then there is an isomorphism $f: M \otimes_R N \cong D$ of abelian groups with $\iota' = f \circ \iota.$ \\ \\
\textbf{Definition - Bimodule}: Let $R$ and $S$ be any rings with 1. An abelian group $M$ is called an \textit{$(S, R)$-bimodule} if $M$ is a left $S$-module, a right $R$-module, and $s(mr) = (sm)r$ for all $s \in S$, $r \in R$ and $m \in M$. \\ \\
\textbf{Definition - Standard $R$-Module}: Suppose $M$ is a left (or right) $R$-module over the commutative ring $R$. Then the $(R, R)$-bimodule structure on $M$ defined by letting the left and right $R$-actions coincide, i.e., $mr = rm$ for all $m \in M$ and $r \in R$, will be called the \textit{standard $R$-module structure} on $M$. \\ \\
\textbf{Definition - $R$-bilinear}: Let $R$ be a commutative ring with 1 and let $M, N$, and $L$ be left $R$-modules. The map $\varphi: M \times N \rightarrow L$ is called \textit{$R$-bilinear} if it is $R$-linear in each factor, i.e., if \begin{align*}
    \varphi(r_1 m_1 + r_2 m_2, n) &= r_1 \varphi(m_1, n) + r_2 \varphi(m_2, n), \text{ and} \\
    \varphi(m, r_1 n_1 + r_2 n_2) &= r_1 \varphi(m, n_1) + r_2 \varphi(m, n_2)
\end{align*} for all $m, m_1, m_2 \in M,$ $n, n_1, n_2 \in N$ and $r_1, r_2 \in R.$ \\ \\
\textbf{Corollary 10.12}: Suppose $R$ is a commutative ring. Let $M$ and $N$ be two left $R$-modules and let $M \otimes_R N$ be the tensor product of $M$ and $N$ over $R$, where $M$ is given the standard $R$-module structure. Then $M \otimes_R N$ is a left $R$-module with $$r(m \otimes n) = (rm) \otimes n = (mr) \otimes n = m \otimes (rn),$$ and the map $\iota: M \times N \rightarrow M \otimes_R N$ with $\iota(m, n) = m \otimes n$ is an $R$-bilinear map. If $L$ is any left $R$-module then there is a bijection $$\begin{Bmatrix}
    R\text{-bilinear maps} \\
    \varphi: M \times N \rightarrow L
\end{Bmatrix} \leftrightarrow \begin{Bmatrix}
    R\text{-module homomorphisms} \\
    \phi: M \otimes_R N \rightarrow L
\end{Bmatrix}$$ where the correspondence between $\varphi$ and $\phi$ is given by the commutative diagram \vspace{-2mm} \begin{figure}[H]
\begin{center}
\includegraphics[scale=0.4]{Cor10.12.png}
\end{center}
\end{figure} \vspace{-2mm}
\noindent \textbf{Theorem 10.13 - The ``Tensor Product'' of Two Homomorphisms}: Let $M, M'$ be right $R$-modules, let $N, N'$ be left $R$-modules, and suppose $\varphi: M \rightarrow M'$ and $\psi: N \rightarrow N'$ are $R$-module homomorphisms. \begin{enumerate}
    \item There is a unique group homomorphism, denoted by $\varphi \otimes \psi$, mapping $M \otimes_R N$ into $M' \otimes_R N'$ such that $(\varphi \otimes \psi)(m \otimes n) = \varphi(m) \otimes \psi(n)$ for all $n \in N, m \in M$.
    \item If $M, M'$ are also $(S, R)$-bimodules for some ring $S$ and $\varphi$ is also an $S$-module homomorphism, then $\varphi \otimes \psi$ is a homomorphism of left $S$-modules. In particular, if $R$ is commutative then $\varphi \otimes \psi$ is always an $R$-module homomorphism for the standard $R$-module structures.
    \item If $\lambda: M' \rightarrow M''$ and $\lambda: N' \rightarrow N''$ are $R$-module homomorphisms then $(\lambda \otimes \mu) \circ (\varphi \otimes \psi) = (\lambda \circ \varphi) \otimes (\mu \circ \psi)$.
\end{enumerate} $ $ \\
\textbf{Theorem 10.14 - Associativity of the Tensor Product}: Suppose $M$ is a right $R$-module, $N$ is an $(R, T)$-bimodule, and $L$ is a left $T$-module. Then there is a unique isomorphism $$(M \otimes_R N) \otimes_T L \cong M \otimes_R (N \otimes_T L)$$ of abelian groups such that $(m \otimes n) \otimes l \mapsto m \otimes (n \otimes l)$. If $M$ is an $(S, R)$-bimodule then this is an isomorphism of $S$-modules. \\ \\
\textbf{Corollary 10.15}: Suppose $R$ is commutative and $M, N$, and $L$ are left $R$-modules. Then $$(M \otimes N) \otimes L \cong M \otimes (N \otimes L)$$ as $R$-modules for the standard $R$-module structures on $M, N$ and $L$. \\ \\
\textbf{Definition - Multilinear}: Let $R$ be a commutative ring with 1 and let $M_1, M_2, \dots, M_n$ and $L$ be
$R$-modules with the standard $R$-module structures. A map $\varphi: M_1 \times \dots \times M_n \rightarrow L$ is
called \textit{$n$-multilinear over $R$} (or simply multilinear if $n$ and $R$ are clear from the context) if it is an $R$-module homomorphism in each component when the other component entries are kept constant, i.e., for each $i$ $$\varphi(m_1, \dots, m_{i - 1}, rm_i + r'm_i', m_{i + 1}, \dots, m_n) = r\varphi(m_1, \dots, m_i, \dots, m_n) + r'\varphi(m_1, \dots m_i' \dots, m_n)$$ for all $m_i, m_i' \in M_i$ and $r, r' \in R$. When n = 2 (respectively, 3) one says $\varphi$ is \textit{bilinear} (respectively \textit{trilinear}) rather than 2-multilinear (or 3-multilinear). \\ \\
\textbf{Corollary 10.16}: Let $R$ be a commutative ring and let $M_1, \dots, M_n, L$ be $R$-modules. Let $M_1 \otimes \dots \otimes M_n$ denote any bracketing of the tensor product of these modules and let $$\iota: M_1 \times \dots \times M_n \rightarrow M_1 \otimes \dots \otimes M_n$$ be the map defined by $\iota(m_1, \dots, m_n) = m_1 \otimes \dots \otimes m_n$. Then \begin{enumerate}
    \item for every $R$-module homomorphism $\phi: M_1 \otimes \dots \otimes M_n \rightarrow L,$ the map $\varphi = \phi \circ \iota$ is $n$-multilinear from $M_1 \times \dots \times M_n$ to $L$, and
    \item if $\varphi: M_1 \times \dots \times M_n \rightarrow L$ is an $n$-multilinear map then there is a unique $R$-module homomorphism $\phi: M_1 \otimes \dots \otimes M_n \rightarrow L$ such that $\varphi = \phi \circ \iota.$
\end{enumerate} Hence there is a bijection $$\begin{Bmatrix}
    n\text{-multilinear maps} \\
    \varphi: M_1 \times \dots \times M_n \rightarrow L
\end{Bmatrix} \leftrightarrow \begin{Bmatrix}
    R\text{-module homomorphisms} \\
    \phi: M_1 \otimes \dots \otimes M_n \rightarrow L
\end{Bmatrix}$$ with respect to which the following diagram commutes: \vspace{-2mm} \begin{figure}[H]
\begin{center}
\includegraphics[scale=0.4]{Cor10.16.png}
\end{center}
\end{figure} \vspace{-5mm}
\noindent \textbf{Theorem 10.17 - Tensor Products of Direct Sums}: Let $M, M'$ be right $R$-modules and let $N, N'$ be left $R$-modules. Then there are unique group isomorphisms \begin{align*}
    (M \oplus M') \otimes_R N &\cong (M \otimes_R N) \oplus (M' \otimes_R N) \\
    M \otimes_R (N \oplus N') &\cong (M \otimes_R N) \oplus (M \otimes_R N')
\end{align*} such that $(m, m') \otimes n \mapsto (m \otimes n, m' \otimes n)$ and $m \otimes (n, n') \mapsto (m \otimes n, m \otimes n')$ respectively. If $M, M'$ are also $(S, R)$-bimodules, then these are isomorphisms of left $S$-modules. In
particular, if $R$ is commutative, these are isomorphisms of $R$-modules. \\ \\
\textbf{Corollary 10.18 - Extension of Scalars for Free Modules}: The module obtained from the free $R$-module $N \cong R^n$ by extension of scalars from $R$ to $S$ is the free $S$-module $S^n$, i.e., $$S \otimes_R R^n \cong S^n$$ as left $S$-modules. \\ \\
\textbf{Corollary 10.19}: Let $R$ be a commutative ring and let $M \cong R^s$ and $N \cong R^t$ be  free $R$-modules with bases $m_1, \dots, m_s$ and $n_1, \dots, n_t$ respectively. Then $M \otimes_R N$ is a free $R$-module of rank $st$, with basis $m_i \otimes n_j, 1 \leq i \leq s$ and $1 \leq j \leq t$, i.e. $$R^s \otimes_R R^t \cong R^{st}.$$ More generally, the tensor product of two free modules of arbitrary rank over
a commutative ring is free. \\ \\
\textbf{Proposition 10.20}: Suppose $R$ is a commutative ring and $M, N$ are left $R$-modules, considered with the standard $R$-module structures. Then there is a unique $R$-module isomorphism $$M \otimes_R N \cong N \otimes_R M$$ mapping $m \otimes n$ to $n \otimes m$. \\ \\
\textbf{Proposition 10.21}: Let $R$ be a commutative ring and let $A$ and $B$ be $R$-algebras. Then the multiplication $(a \otimes b)(a' \otimes b') = aa' \otimes bb'$ is well defined and makes $A \otimes_R B$ into an $R$-algebra. \\ \\

































\end{document}